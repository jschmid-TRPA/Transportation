{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup \n",
    "# import modules\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "import arcpy\n",
    "import numpy as np\n",
    "import urllib\n",
    "#import geojson\n",
    "#import json\n",
    "#from urllib.request import urlopen\n",
    "from arcgis.features import FeatureSet, GeoAccessor, GeoSeriesAccessor\n",
    "#Test 2\n",
    "# setup workspace folder\n",
    "workspace = \"//Trpa-fs01/gis/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/\"\n",
    "\n",
    "# setup environment variables\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = \"//Trpa-fs01/GIS/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/CrashData/CrashData.gdb\"\n",
    "\n",
    "# create a spatial reference object for the output coordinate system \n",
    "# output projection for data going into SDE should be UTM Zone 10N (EPSG: 26910)\n",
    "out_coordinate_system = arcpy.SpatialReference(26910)\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"//Trpa-fs01/GIS/DB_CONNECT\"\n",
    "\n",
    "# database file path \n",
    "sdeBase  = os.path.join(filePath, \"Vector.sde\")\n",
    "\n",
    "# SDE feature classes needed for spatial joins\n",
    "corridor = os.path.join(sdeBase, 'sde.SDE.Transportation\\sde.SDE.Corridor')\n",
    "trpa     = os.path.join(sdeBase, 'sde.SDE.Jurisdictions\\sde.SDE.TRPA_bdy')\n",
    "\n",
    "# define csv lat/long field names for xy table to point\n",
    "x_coords = 'POINT_X'\n",
    "y_coords = 'POINT_Y'\n",
    "\n",
    "# SDE feature class to update\n",
    "crashSDE  = os.path.join(sdeBase, 'sde.SDE.Transportation\\sde.SDE.Highway_Collisions')\n",
    "\n",
    "# Get Crash Data\n",
    "caCrashes = os.path.join(workspace, \"BothCACounties_Crashes_1320_Unclean_v2.csv\")\n",
    "dfCACrash = pd.read_csv(caCrashes)\n",
    "\n",
    "nvCrashes = os.path.join(workspace, \"NV_LAKE TAHOE BASIN - ALL ROADS 2013-2020.csv\")\n",
    "dfNVCrash = pd.read_csv(nvCrashes)\n",
    "    \n",
    "# # in memory files\n",
    "memory = \"memory\" + \"\\\\\"\n",
    "\n",
    "# replaces features in outfc with exact same schema\n",
    "def updateSDE(inputfc,outfc, fieldnames):\n",
    "        # disconnect all users\n",
    "    print(\"\\nDisconnecting all users...\")\n",
    "    arcpy.DisconnectUser(sde, \"ALL\")\n",
    "\n",
    "    # deletes all rows from the SDE feature class\n",
    "    arcpy.TruncateTable_management(outfc)\n",
    "    print (\"\\nDeleted all records in: {}\\n\".format(outfc))\n",
    "\n",
    "    # insert rows from Temporary feature class to SDE feature class\n",
    "    with arcpy.da.InsertCursor(outfc, fieldnames) as oCursor:\n",
    "        count = 0\n",
    "        with arcpy.da.SearchCursor(inputfc, fieldnames) as iCursor:\n",
    "            for row in iCursor:\n",
    "                oCursor.insertRow(row)\n",
    "                count += 1\n",
    "                if count % 1000 == 0:\n",
    "                    print(\"Inserting record {0} into SDE table\".format(count))\n",
    "\n",
    "    # disconnect all users\n",
    "    print(\"\\nDisconnecting all users...\")\n",
    "    arcpy.DisconnectUser(sde, \"ALL\")\n",
    "    # confirm feature class was created\n",
    "    print(\"\\nUpdated \" + outfc)\n",
    "    \n",
    "# function to move spatial join data to parcel master staging\n",
    "def fieldJoinCalc(updateFC, updateFieldsList, sourceFC, sourceFieldsList):\n",
    "    from time import strftime  \n",
    "    print (\"Started data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#     log.info(\"Started data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Use list comprehension to build a dictionary from arcpy SearchCursor  \n",
    "    valueDict = {r[0]:(r[1:]) for r in arcpy.da.SearchCursor(sourceFC, sourceFieldsList)}  \n",
    "   \n",
    "    with arcpy.da.UpdateCursor(updateFC, updateFieldsList) as updateRows:  \n",
    "        for updateRow in updateRows:  \n",
    "            # store the Join value of the row being updated in a keyValue variable  \n",
    "            keyValue = updateRow[0]  \n",
    "            # verify that the keyValue is in the Dictionary  \n",
    "            if keyValue in valueDict:  \n",
    "                # transfer the value stored under the keyValue from the dictionary to the updated field.  \n",
    "                updateRow[1] = valueDict[keyValue][0]  \n",
    "                updateRows.updateRow(updateRow)    \n",
    "    del valueDict  \n",
    "    print (\"Finished data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#     log.info(\"Finished data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
