{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up initial data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup \n",
    "# import modules\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import arcpy\n",
    "import numpy as np\n",
    "import urllib\n",
    "\n",
    "ca_crash_input_file = 'BothCACounties_Crashes_1321_Unclean.csv'\n",
    "nv_crash_input_file = 'NV_LAKE TAHOE BASIN - ALL ROADS 2013-2020.csv'\n",
    "# setup workspace folder\n",
    "workspace = \"F:/gis/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/\"\n",
    "\n",
    "# setup environment variables\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = \"F:/GIS/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/CrashData/CrashData.gdb\"\n",
    "\n",
    "# create a spatial reference object for the output coordinate system \n",
    "# output projection for data going into SDE should be UTM Zone 10N (EPSG: 26910)\n",
    "out_coordinate_system = arcpy.SpatialReference(26910)\n",
    "\n",
    "# network path to connection files\n",
    "filePath = \"F:/GIS/DB_CONNECT\"\n",
    "\n",
    "# database file path \n",
    "sdeBase  = os.path.join(filePath, \"Vector.sde\")\n",
    "\n",
    "# SDE feature classes needed for spatial joins\n",
    "corridor = os.path.join(sdeBase, 'sde.SDE.Transportation\\sde.SDE.Corridor')\n",
    "trpa     = os.path.join(sdeBase, 'sde.SDE.Jurisdictions\\sde.SDE.TRPA_bdy')\n",
    "\n",
    "# define csv lat/long field names for xy table to point\n",
    "x_coords = 'POINT_X'\n",
    "y_coords = 'POINT_Y'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import raw data and sde highway collisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_7404\\3716292085.py:6: DtypeWarning: Columns (6,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dfCACrash = pd.read_csv(caCrashes)\n"
     ]
    }
   ],
   "source": [
    "# SDE feature class to update\n",
    "crashSDE  = os.path.join(sdeBase, 'sde.SDE.Transportation\\sde.SDE.Highway_Collisions')\n",
    "\n",
    "# Get Crash Data\n",
    "caCrashes = os.path.join(workspace, \"BothCACounties_Crashes_1320_Unclean_v2.csv\")\n",
    "dfCACrash = pd.read_csv(caCrashes)\n",
    "\n",
    "nvCrashes = os.path.join(workspace, \"NV_LAKE TAHOE BASIN - ALL ROADS 2013-2020.csv\")\n",
    "dfNVCrash = pd.read_csv(nvCrashes)\n",
    "    \n",
    "# # in memory files\n",
    "memory = \"memory\" + \"\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CA data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9665    0\n",
      "9666    0\n",
      "9667    0\n",
      "9668    0\n",
      "9669    0\n",
      "Name: Num_Motorcyclist_Killed, Length: 9670, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## CA data translation\n",
    "# convert date/time and case info\n",
    "#convert state/county/city, year/date/time\n",
    "dfCACrash['State']       = \"CA\"\n",
    "dfCACrash['City']        = dfCACrash['CITY']\n",
    "dfCACrash['County']      = dfCACrash['COUNTY']\n",
    "dfCACrash['Year']        = dfCACrash['ACCIDENT_YEAR']\n",
    "dfCACrash['Date']        = dfCACrash['COLLISION_DATE']\n",
    "dfCACrash['4DigTime']    = dfCACrash['COLLISION_TIME'].astype(str).str.zfill(4)\n",
    "dfCACrash['Hour']        = dfCACrash['4DigTime'].str[:2]\n",
    "dfCACrash['Min']         = dfCACrash['4DigTime'].str[2:]\n",
    "dfCACrash['Time']        = dfCACrash['Hour']+\":\"+dfCACrash['Min']\n",
    "dfCACrash['Data_Source'] = \"CHP/SWITRS\"\n",
    "\n",
    "#Convert severity\n",
    "dfCACrash.loc[dfCACrash['COLLISION_SEVERITY'].isin([1]),  'Crash_Severity'] = 'Fatal'\n",
    "dfCACrash.loc[dfCACrash['COLLISION_SEVERITY'].isin([2]),  'Crash_Severity'] = 'Severe injury'\n",
    "dfCACrash.loc[dfCACrash['COLLISION_SEVERITY'].isin([3]),  'Crash_Severity'] = 'Other visible injury'\n",
    "dfCACrash.loc[dfCACrash['COLLISION_SEVERITY'].isin([4]),  'Crash_Severity'] = 'Complaint of pain'\n",
    "dfCACrash.loc[dfCACrash['COLLISION_SEVERITY'].isin([0]),  'Crash_Severity'] = 'Property damage only'\n",
    "#Convert crash type\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"A\"]),  'Crash_Type'] = 'Head-on'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"B\"]),  'Crash_Type'] = 'Sideswipe'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"C\"]),  'Crash_Type'] = 'Rear end'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"D\"]),  'Crash_Type'] = 'Angle-broadside'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"E\"]),  'Crash_Type'] = 'Hit object'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"F\"]),  'Crash_Type'] = 'Overturned'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"G\"]),  'Crash_Type'] = 'Vehicle/pedestrian'\n",
    "dfCACrash.loc[dfCACrash['TYPE_OF_COLLISION'].isin([\"H\"]),  'Crash_Type'] = 'Other'\n",
    "#convert lighting\n",
    "dfCACrash.loc[dfCACrash['LIGHTING'].isin([\"A\"]),  'Lighting'] = \"Daylight\"\n",
    "dfCACrash.loc[dfCACrash['LIGHTING'].isin([\"B\"]),  'Lighting'] = \"Dusk - Dawn\"\n",
    "dfCACrash.loc[dfCACrash['LIGHTING'].isin([\"C\"]),  'Lighting'] = \"Dark - Street Lights\"\n",
    "dfCACrash.loc[dfCACrash['LIGHTING'].isin([\"D\"]),  'Lighting'] = \"Dark - No Street Lights\"\n",
    "dfCACrash.loc[dfCACrash['LIGHTING'].isin([\"E\"]),  'Lighting'] = \"Dark - Street Lights Not Functioning\"\n",
    "dfCACrash.loc[dfCACrash['LIGHTING'].isin([\"-\"]),  'Lighting'] = \"Not Stated\"\n",
    "#Convert weather 1\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"A\"]),  'Weather_1'] = \"Clear\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"B\"]),  'Weather_1'] = \"Cloudy\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"C\"]),  'Weather_1'] = \"Raining\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"D\"]),  'Weather_1'] = \"Snowing\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"E\"]),  'Weather_1'] = \"Fog\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"F\"]),  'Weather_1'] = \"Other\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"G\"]),  'Weather_1'] = \"Windy\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_1'].isin([\"-\"]),  'Weather_1'] = \"Not Stated\"\n",
    "# convert weather 2\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"A\"]),  'Weather_2'] = \"Clear\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"B\"]),  'Weather_2'] = \"Cloudy\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"C\"]),  'Weather_2'] = \"Raining\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"D\"]),  'Weather_2'] = \"Snowing\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"E\"]),  'Weather_2'] = \"Fog\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"F\"]),  'Weather_2'] = \"Other\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"G\"]),  'Weather_2'] = \"Windy\"\n",
    "dfCACrash.loc[dfCACrash['WEATHER_2'].isin([\"-\"]),  'Weather_2'] = \"Not Stated\"\n",
    "#Convert violation\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"0\"]),  'Violation'] = \"Unknown\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"1\"]),  'Violation'] = \"Driving/Biking Under the Influence\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"2\"]),  'Violation'] = \"Impeding Traffic\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"3\"]),  'Violation'] = \"Unsafe Speed\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"4\"]),  'Violation'] = \"Following Too Closely\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"5\"]),  'Violation'] = \"Wrong Side of Road\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"6\"]),  'Violation'] = \"Improper Passing\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"7\"]),  'Violation'] = \"Unsafe Lane Change\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"8\"]),  'Violation'] = \"Improper Turning\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"9\"]),  'Violation'] = \"Auotomobile Right of Way\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"10\"]),  'Violation'] = \"Pedestrian Right of Way\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"11\"]),  'Violation'] = \"Pedestrian Violation\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"12\"]),  'Violation'] = \"Traffic Signals and Signs\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"13\"]),  'Violation'] = \"Hazardous Parking\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"17\"]),  'Violation'] = \"Other Hazardous Violation\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"18\"]),  'Violation'] = \"Other Than Driver or Pedestrian\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"21\"]),  'Violation'] = \"Unsafe Backing or Starting\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"22\"]),  'Violation'] = \"Other Improper Driving\"\n",
    "dfCACrash.loc[dfCACrash['PCF_VIOL_CATEGORY'].isin([\"-\"]),  'Violation'] = \"Not Stated\"\n",
    "#Convert road surface\n",
    "dfCACrash.loc[dfCACrash['ROAD_SURFACE'].isin([\"A\"]),  'Road_Surface'] = \"Dry\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_SURFACE'].isin([\"B\"]),  'Road_Surface'] = \"Wet\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_SURFACE'].isin([\"C\"]),  'Road_Surface'] = \"Snowy or Icy\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_SURFACE'].isin([\"D\"]),  'Road_Surface'] = \"Slippery (Muddy, Oily, etc.)\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_SURFACE'].isin([\"-\"]),  'Road_Surface'] = \"Not Stated\"\n",
    "#Convert road condition 1\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"A\"]),  'Road_Condition_1'] = \"Holes, Deep Ruts\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"B\"]),  'Road_Condition_1'] = \"Loose Material on Roadway\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"C\"]),  'Road_Condition_1'] = \"Obstruction on Roadway\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"D\"]),  'Road_Condition_1'] = \"Construction or Repair Zone\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"E\"]),  'Road_Condition_1'] = \"Reduced Roadway Width\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"F\"]),  'Road_Condition_1'] = \"Flooded\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"G\"]),  'Road_Condition_1'] = \"Other\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"H\"]),  'Road_Condition_1'] = \"No Unusual Condition\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_1'].isin([\"-\"]),  'Road_Condition_1'] = \"Not Stated\"\n",
    "# conver road condition 2\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"A\"]),  'Road_Condition_2'] = \"Holes, Deep Ruts\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"B\"]),  'Road_Condition_2'] = \"Loose Material on Roadway\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"C\"]),  'Road_Condition_2'] = \"Obstruction on Roadway\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"D\"]),  'Road_Condition_2'] = \"Construction or Repair Zone\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"E\"]),  'Road_Condition_2'] = \"Reduced Roadway Width\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"F\"]),  'Road_Condition_2'] = \"Flooded\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"G\"]),  'Road_Condition_2'] = \"Other\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"H\"]),  'Road_Condition_2'] = \"No Unusual Condition\"\n",
    "dfCACrash.loc[dfCACrash['ROAD_COND_2'].isin([\"-\"]),  'Road_Condition_2'] = \"Not Stated\"\n",
    "#Convert pedestrian action\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"A\"]),  'Pedestrian_Action'] = \"No Pedestrian Involved\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"B\"]),  'Pedestrian_Action'] = \"Crossing in Crosswalk at Intersection\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"C\"]),  'Pedestrian_Action'] = \"Crossing in Crosswalk Not at Intersection\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"D\"]),  'Pedestrian_Action'] = \"Crossing Not in Crosswalk\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"E\"]),  'Pedestrian_Action'] = \"In Road, Including Shoulder\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"F\"]),  'Pedestrian_Action'] = \"Not in Road\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"G\"]),  'Pedestrian_Action'] = \"Approaching/Leaving School Bus\"\n",
    "dfCACrash.loc[dfCACrash['PED_ACTION'].isin([\"-\"]),  'Pedestrian_Action'] = \"Not Stated\"\n",
    "#Convert hit and run\n",
    "dfCACrash.loc[dfCACrash['HIT_AND_RUN'].isin([\"F\"]), 'Hit_and_Run'] = \"Felony\"\n",
    "dfCACrash.loc[dfCACrash['HIT_AND_RUN'].isin([\"M\"]), 'Hit_and_Run'] = \"Misdemeanor\"\n",
    "dfCACrash.loc[dfCACrash['HIT_AND_RUN'].isin([\"N\"]), 'Hit_and_Run'] = \"Not Hit and Run\"\n",
    "#Convert MVIW\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"A\"]), 'Motor_Vehicle_Interacted_With'] = \"Non-Collision\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"B\"]), 'Motor_Vehicle_Interacted_With'] = \"Pedestrian\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"C\"]), 'Motor_Vehicle_Interacted_With'] = \"Other Motor Vehicle\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"D\"]), 'Motor_Vehicle_Interacted_With'] = \"Motor Vehicle on Other Roadway\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"E\"]), 'Motor_Vehicle_Interacted_With'] = \"Parked Motor Vehicle\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"F\"]), 'Motor_Vehicle_Interacted_With'] = \"Train\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"G\"]), 'Motor_Vehicle_Interacted_With'] = \"Bicycle\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"H\"]), 'Motor_Vehicle_Interacted_With'] = \"Animal\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"I\"]), 'Motor_Vehicle_Interacted_With'] = \"Fixed Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"J\"]), 'Motor_Vehicle_Interacted_With'] = \"Other Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"0\"]), 'Motor_Vehicle_Interacted_With'] = \"Non-Collision and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"1\"]), 'Motor_Vehicle_Interacted_With'] = \"Pedestrian and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"2\"]), 'Motor_Vehicle_Interacted_With'] = \"Other Motor Vehicle and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"3\"]), 'Motor_Vehicle_Interacted_With'] = \"Motor Vehicle on Other Roadway and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"4\"]), 'Motor_Vehicle_Interacted_With'] = \"Parked Motor Vehicle and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"5\"]), 'Motor_Vehicle_Interacted_With'] = \"Train and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"6\"]), 'Motor_Vehicle_Interacted_With'] = \"Bicycle and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"7\"]), 'Motor_Vehicle_Interacted_With'] = \"Animal and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"8\"]), 'Motor_Vehicle_Interacted_With'] = \"Fixed Object and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"9\"]), 'Motor_Vehicle_Interacted_With'] = \"Other Object and Additional Object\"\n",
    "dfCACrash.loc[dfCACrash['MVIW'].isin([\"-\"]), 'Motor_Vehicle_Interacted_With'] = \"Not Stated\"\n",
    "#convert case ID\n",
    "dfCACrash['CA_Case_ID']            = dfCACrash['CASE_ID']\n",
    "dfCACrash['NV_Accident_Num']       = np.nan\n",
    "dfCACrash['NV_Accident_Rec_Num']   = np.nan\n",
    "#Convert number injured/killed\n",
    "dfCACrash['Num_Killed']            = dfCACrash['NUMBER_KILLED']\n",
    "dfCACrash['Num_Injured']           = dfCACrash['NUMBER_INJURED']\n",
    "dfCACrash['Num_Ped_Killed']        = dfCACrash['COUNT_PED_KILLED']\n",
    "dfCACrash['Num_Ped_Injured']       = dfCACrash['COUNT_PED_INJURED']\n",
    "dfCACrash['Num_Bicyclist_Killed']  = dfCACrash['COUNT_BICYCLIST_KILLED']\n",
    "dfCACrash['Num_Bicyclist_Injured'] = dfCACrash['COUNT_BICYCLIST_INJURED']\n",
    "dfCACrash['Num_Motorcyclist_Killed']  = dfCACrash['COUNT_MC_KILLED']\n",
    "dfCACrash['Num_Motorcyclist_Injured'] = dfCACrash['COUNT_MC_INJURED']\n",
    "print(dfCACrash['Num_Motorcyclist_Killed'])\n",
    "#Convert number vehicles/parties\n",
    "dfCACrash['Num_Vehicles']          = np.nan\n",
    "dfCACrash['Num_Parties']           = dfCACrash['PARTY_COUNT']\n",
    "#Convert alcohol/bike/ped involvement\n",
    "dfCACrash['Alcohol_Involved']      = dfCACrash['ALCOHOL_INVOLVED']\n",
    "dfCACrash['Pedestrian_Involved']   = dfCACrash['PEDESTRIAN_ACCIDENT']\n",
    "dfCACrash['Bicycle_Involved']      = dfCACrash['BICYCLE_ACCIDENT']\n",
    "dfCACrash['Motorcycle_Involved']   = dfCACrash['MOTORCYCLE_ACCIDENT']\n",
    "dfCACrash['Corridor_ID']           = np.nan\n",
    "\n",
    "# final list of fields\n",
    "dfCACrash = dfCACrash[['State',\n",
    "           'CA_Case_ID',\n",
    "           'NV_Accident_Num',\n",
    "           'NV_Accident_Rec_Num',\n",
    "           'Corridor_ID',\n",
    "           'County',\n",
    "           'City',\n",
    "           'Year',\n",
    "           'Date',\n",
    "           'Time',\n",
    "           'Weather_1',\n",
    "           'Weather_2',\n",
    "           'Crash_Severity',\n",
    "           'Num_Killed',\n",
    "           'Num_Injured',\n",
    "           'Num_Ped_Killed',\n",
    "           'Num_Ped_Injured',\n",
    "           'Num_Bicyclist_Killed',\n",
    "           'Num_Bicyclist_Injured',\n",
    "           'Num_Motorcyclist_Killed',\n",
    "           'Num_Motorcyclist_Injured',\n",
    "           'Crash_Type',\n",
    "           'Num_Vehicles',\n",
    "           'Num_Parties',\n",
    "           'Violation',\n",
    "           'Hit_and_Run',\n",
    "           'Motor_Vehicle_Interacted_With',\n",
    "           'Pedestrian_Action', \n",
    "           'Road_Condition_1',\n",
    "           'Road_Condition_2',\n",
    "           'Road_Surface',\n",
    "           'Lighting',\n",
    "           'Pedestrian_Involved',\n",
    "           'Bicycle_Involved',\n",
    "           'Motorcycle_Involved',\n",
    "           'Alcohol_Involved',\n",
    "           'Data_Source',\n",
    "           'POINT_X',\n",
    "           'POINT_Y']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NV data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NV Data Transformation\n",
    "# set fields for time and case info\n",
    "dfNVCrash['CA_Case_ID']           = np.nan\n",
    "dfNVCrash['NV_Accident_Num']      = dfNVCrash['NV Accident Num']\n",
    "dfNVCrash['NV_Accident_Rec_Num']  = dfNVCrash['NV Accident Rec Num']\n",
    "dfNVCrash['City']                 = np.nan\n",
    "dfNVCrash['Year']                 = dfNVCrash['Collision_Year']\n",
    "dfNVCrash['Date']                 = dfNVCrash['Collision_Date']\n",
    "dfNVCrash['Time']                 = dfNVCrash['Collision_Time']\n",
    "dfNVCrash['Num_Vehicles']         = dfNVCrash['Total Vehicles']\n",
    "dfNVCrash['Num_Parties']          = np.nan\n",
    "dfNVCrash['Data_Source']          = \"NDOT\"\n",
    "\n",
    "# Convert NV crash type and severity\n",
    "dfNVCrash['Crash_Severity']       = dfNVCrash['COLLISION_SEVERITY']\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"ANGLE\"]),  'Crash_Type']         = 'Angle-broadside'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"BACKING\"]),  'Crash_Type']       = 'Backing'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"HEAD-ON\"]),  'Crash_Type']       = 'Head-on'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"NON-COLLISION\"]),  'Crash_Type'] = 'Non-collision'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"REAR-END\"]),  'Crash_Type']      = 'Rear end'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"REAR-TO-REAR\"]),  'Crash_Type']  = 'Other'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"SIDESWIPE, MEETING\"]),  'Crash_Type'] = 'Sideswipe'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"SIDESWIPE, OVERTAKING\"]),  'Crash_Type'] = 'Sideswipe'\n",
    "dfNVCrash.loc[dfNVCrash['Crash Type'].isin([\"UNKNOWN\"]),  'Crash_Type'] = 'Unknown'\n",
    "#Convert # injured/killed\n",
    "dfNVCrash['Num_Killed']   = dfNVCrash['Fatalities']\n",
    "dfNVCrash['Num_Killed'].fillna(0)\n",
    "dfNVCrash['Num_Injured'] = dfNVCrash['Injured']\n",
    "dfNVCrash['Num_Injured'].fillna(0)\n",
    "dfNVCrash['Num_Ped_Killed'] = np.nan\n",
    "dfNVCrash['Num_Ped_Injured'] = np.nan\n",
    "dfNVCrash['Num_Bicyclist_Killed'] = np.nan\n",
    "dfNVCrash['Num_Bicyclist_Injured'] = np.nan\n",
    "dfNVCrash['Num_Motorcyclist_Killed'] = np.nan\n",
    "dfNVCrash['Num_Motorcyclist_Injured'] = np.nan\n",
    "# convert crash info\n",
    "dfNVCrash['Violation']  = \"N/A\"\n",
    "dfNVCrash['Hit_and_Run'] = \"N/A\"\n",
    "dfNVCrash['Motor_Vehicle_Interacted_With'] = \"N/A\"\n",
    "dfNVCrash['Pedestrian_Action'] = \"N/A\"\n",
    "# Process lighting\n",
    "dfNVCrash['Lighting'] = dfNVCrash['LIGHTING']\n",
    "dfNVCrash.loc[dfNVCrash['Lighting'].isin([\"Dusk-Dawn\"]),  'Lighting'] = \"Dusk - Dawn\"\n",
    "dfNVCrash.loc[dfNVCrash['Lighting'].isin([\"Dusk-dawn\"]),  'Lighting'] = \"Dusk - Dawn\"\n",
    "dfNVCrash.loc[dfNVCrash['Lighting'].isin([\"Dark - street lights\"]),  'Lighting'] = \"Dark - Street Lights\"\n",
    "dfNVCrash.loc[dfNVCrash['Lighting'].isin([\"Dark - no street lights\"]),  'Lighting'] = \"Dark - No Street Lights\"\n",
    "dfNVCrash.loc[dfNVCrash['Lighting'].isin([\"Dark - Unknown Lighting\"]),  'Lighting'] = \"Dark - Unknown Lighting\"\n",
    "dfNVCrash.loc[dfNVCrash['Lighting'].isin([\"Not stated\"]),  'Lighting'] = \"Not Stated\"\n",
    "#Process alcohol involvement (check outputs)\n",
    "dfNVCrash['V1 Driver Factors'] = dfNVCrash['V1 Driver Factors'].fillna(\"Not stated\")\n",
    "dfNVCrash['V2 Driver Factors'] = dfNVCrash['V2 Driver Factors'].fillna(\"Not stated\")\n",
    "dfNVCrash.loc[dfNVCrash['V1 Driver Factors'].str.contains(\"DRINKING\"), 'Alcohol_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V2 Driver Factors'].str.contains(\"DRINKING\"), 'Alcohol_Involved'] = \"Y\"\n",
    "#Process bike/ped involvement (check outputs)\n",
    "dfNVCrash['V1 All Events'] = dfNVCrash['V1 All Events'].fillna(\"Not stated\")\n",
    "dfNVCrash['V2 All Events'] = dfNVCrash['V2 All Events'].fillna(\"Not stated\")\n",
    "dfNVCrash.loc[dfNVCrash['V1 All Events'].str.contains(\"PEDESTRIAN\"), 'Pedestrian_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V2 All Events'].str.contains(\"PEDESTRIAN\"), 'Pedestrian_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V1 All Events'].str.contains(\"PEDAL CYCLE\"), 'Bicycle_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V2 All Events'].str.contains(\"PEDAL CYCLE\"), 'Bicycle_Involved'] = \"Y\"\n",
    "#Process motorcycle involvement (check outputs)\n",
    "dfNVCrash['V1 Type'] = dfNVCrash['V1 Type'].fillna(\"Not stated\")\n",
    "dfNVCrash['V2 Type'] = dfNVCrash['V1 Type'].fillna(\"Not stated\")\n",
    "dfNVCrash.loc[dfNVCrash['V1 Type'].str.contains(\"MOTORCYCLE\"), 'Motorcycle_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V1 Type'].str.contains(\"MOTORBIKE\"), 'Motorcycle_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V1 Type'].str.contains(\"MOPED\"), 'Motorcycle_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V2 Type'].str.contains(\"MOTORCYCLE\"), 'Motorcycle_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V2 Type'].str.contains(\"MOTORBIKE\"), 'Motorcycle_Involved'] = \"Y\"\n",
    "dfNVCrash.loc[dfNVCrash['V2 Type'].str.contains(\"MOPED\"), 'Motorcycle_Involved'] = \"Y\"\n",
    "# #Convert road surface\n",
    "dfNVCrash['Factors Roadway'] = dfNVCrash['Factors Roadway'].fillna(\"Not stated\")\n",
    "dfNVCrash['HWY Factors'] = dfNVCrash['HWY Factors'].fillna(\"Not stated\")\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"DRY\"), 'Road_Surface'] = \"Dry\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"WET\"), 'Road_Surface'] = \"Wet\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"WATER\"), 'Road_Surface'] = \"Wet\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"ICE\"), 'Road_Surface'] = \"Snowy or Icy\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"SNOW\"), 'Road_Surface'] = \"Snowy or Icy\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"SLUSH\"), 'Road_Surface'] = \"Snowy or Icy\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"OTHER\"), 'Road_Surface'] = \"Other\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"NA\"), 'Road_Surface'] = \"Not stated\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"UNKNOWN\"), 'Road_Surface'] = \"Unknown\"\n",
    "dfNVCrash.loc[dfNVCrash['Factors Roadway'].str.contains(\"Not stated\"), 'Road_Surface'] = \"Not stated\"\n",
    "#Convert road condition\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"NONE\"), 'Road_Condition_1'] = \"No Unusual Condition\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"UNKNOWN\"), 'Road_Condition_1'] = \"Unknown\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"WET, ICY, SNOW, SLUSH\"), 'Road_Condition_1'] = \"Weather\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"WEATHER\"), 'Road_Condition_1'] = \"Weather\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"BACKUP\"), 'Road_Condition_1'] = \"Other\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"GLARE\"), 'Road_Condition_1'] = \"Other\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"OTHER\"), 'Road_Condition_1'] = \"Other\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"VISUAL OBSTRUCTION\"), 'Road_Condition_1'] = \"Other\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"ROAD OBSTRUCTION\"), 'Road_Condition_1'] = \"Obstruction on Roadway\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"DEBRIS\"), 'Road_Condition_1'] = \"Loose Material on Roadway\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"WORK ZONE\"), 'Road_Condition_1'] = \"Construction or Repair Zone\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"ANIMAL\"), 'Road_Condition_1'] = \"Wildlife\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"RUTS\"), 'Road_Condition_1'] = \"Holes, Deep Ruts\"\n",
    "dfNVCrash.loc[dfNVCrash['HWY Factors'].str.contains(\"Not stated\"), 'Road_Condition_1'] = \"Not Stated\"\n",
    "dfNVCrash['Road_Condition_2'] = np.nan\n",
    "\n",
    "#Rename to match CA data\n",
    "dfNVCrash['Weather_1']   = dfNVCrash['Weather']\n",
    "dfNVCrash['Weather_2']   = np.nan\n",
    "dfNVCrash['POINT_X']     = dfNVCrash['X']\n",
    "dfNVCrash['POINT_Y']     = dfNVCrash['Y']\n",
    "dfNVCrash['Corridor_ID'] = np.nan\n",
    "\n",
    "# final list of fields\n",
    "dfNVCrash = dfNVCrash[['State',\n",
    "           'CA_Case_ID',\n",
    "           'NV_Accident_Num',\n",
    "           'NV_Accident_Rec_Num',\n",
    "           'Corridor_ID',\n",
    "           'County',\n",
    "           'City',\n",
    "           'Year',\n",
    "           'Date',\n",
    "           'Time',\n",
    "           'Weather_1',\n",
    "           'Weather_2',\n",
    "           'Crash_Severity',\n",
    "           'Num_Killed',\n",
    "           'Num_Injured',\n",
    "           'Num_Ped_Killed',\n",
    "           'Num_Ped_Injured',\n",
    "           'Num_Bicyclist_Killed',\n",
    "           'Num_Bicyclist_Injured',\n",
    "           'Crash_Type',\n",
    "           'Num_Vehicles',\n",
    "           'Num_Parties',\n",
    "           'Violation',\n",
    "           'Hit_and_Run',\n",
    "           'Motor_Vehicle_Interacted_With',\n",
    "           'Pedestrian_Action', \n",
    "           'Road_Condition_1',\n",
    "           'Road_Condition_2',\n",
    "           'Road_Surface',\n",
    "           'Lighting',\n",
    "           'Pedestrian_Involved',\n",
    "           'Bicycle_Involved',\n",
    "           'Motorcycle_Involved',\n",
    "           'Alcohol_Involved',\n",
    "           'Data_Source',\n",
    "           'POINT_X',\n",
    "           'POINT_Y']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crash Feature Classes Merged\n",
      "Started data transfer: 2023-12-18 16:14:48\n",
      "Finished data transfer: 2023-12-18 16:14:53\n",
      "Finished updating staging layer\n",
      "features deleted\n"
     ]
    }
   ],
   "source": [
    "# os.remove(os.path.join(workspace, \"NV_Crash_New.csv\" ))\n",
    "\n",
    "# export dataframe to csv \n",
    "dfNVCrash.to_csv(os.path.join(workspace, \"NV_Crash_New.csv\" ))\n",
    "# get NV CSV for XY Table TO Point\n",
    "nvCSV = os.path.join(workspace, \"NV_Crash_New.csv\" )\n",
    "\n",
    "# name the output feature class\n",
    "nvFC  = 'NV_Crash_New_1'\n",
    "\n",
    "\n",
    "\n",
    "# Nevada data frame to feature class \n",
    "# input data is in NAD 1983 UTM Zone 11N coordinate system\n",
    "arcpy.management.XYTableToPoint(nvCSV, nvFC, \n",
    "                                x_coords, y_coords, \"\",\n",
    "                                # set prjoection transform to from\n",
    "                                arcpy.SpatialReference(26911))\n",
    "\n",
    "# output data for project tool\n",
    "output_NV_Crash_Project = \"NV_Crash_Project_1\"\n",
    "\n",
    "# project from UTM to WGS\n",
    "arcpy.Project_management(nvFC, output_NV_Crash_Project, out_coordinate_system)\n",
    "\n",
    "# os.remove(os.path.join(workspace, \"CA_Crash_New.csv\"))\n",
    "## CA Export\n",
    "# export dataframe to csv \n",
    "dfCACrash.to_csv(os.path.join(workspace, \"CA_Crash_New.csv\" ))\n",
    "\n",
    "# get NV CSV for XY Table TO Point\n",
    "caCSV = os.path.join(workspace, \"CA_Crash_New.csv\" )\n",
    "\n",
    "# name the output feature class\n",
    "caFC     = 'CA_Crash_New_1'\n",
    "\n",
    "# CA data frame to feature class\n",
    "arcpy.management.XYTableToPoint(caCSV, caFC, \n",
    "                                x_coords, y_coords, \"\",\n",
    "                                # set prjoection transform to from\n",
    "                                arcpy.SpatialReference(4326))\n",
    "\n",
    "# output data for project tool\n",
    "output_CA_Crash_Project = \"CA_Crash_Project_1\" \n",
    "\n",
    "# project from UTM to WGS\n",
    "arcpy.Project_management(caFC, output_CA_Crash_Project, out_coordinate_system)\n",
    "\n",
    "## Merge CA and NV\n",
    "# out merge fc\n",
    "tahoeCrash = \"Tahoe_Crash_1\"\n",
    "\n",
    "# input feature classes\n",
    "caCrash = \"CA_Crash_Project_1\"\n",
    "nvCrash = \"NV_Crash_Project_1\"\n",
    "\n",
    "# Create FieldMappings object to manage merge output fields\n",
    "fieldMappings = arcpy.FieldMappings()\n",
    "# Add all fields from all parcel staging layers\n",
    "fieldMappings.addTable(caCrash)\n",
    "fieldMappings.addTable(nvCrash)\n",
    "\n",
    "# Remove all output fields from the field mappings, except fields in field_master list\n",
    "for field in fieldMappings.fields:\n",
    "    if field.name not in [  'OBJECTID',\n",
    "                            'State',\n",
    "                            'CA_Case_ID',\n",
    "                            'NV_Accident_Num',\n",
    "                            'NV_Accident_Rec_Num',\n",
    "                            'Corridor_ID',\n",
    "                            'County',\n",
    "                            'City',\n",
    "                            'Year',\n",
    "                            'Date',\n",
    "                            'Time',\n",
    "                            'Weather_1',\n",
    "                            'Weather_2',\n",
    "                            'Crash_Severity',\n",
    "                            'Num_Killed',\n",
    "                            'Num_Injured',\n",
    "                            'Num_Ped_Killed',\n",
    "                            'Num_Ped_Injured',\n",
    "                            'Num_Bicyclist_Killed',\n",
    "                            'Num_Bicyclist_Injured',\n",
    "                            'Num_Motorcyclist_Killed',\n",
    "                            'Num_Motorcyclist_Injured',\n",
    "                            'Crash_Type',\n",
    "                            'Num_Vehicles',\n",
    "                            'Num_Parties',\n",
    "                            'Violation',\n",
    "                            'Hit_and_Run',\n",
    "                            'Motor_Vehicle_Interacted_With',\n",
    "                            'Pedestrian_Action', \n",
    "                            'Road_Condition_1',\n",
    "                            'Road_Condition_2',\n",
    "                            'Road_Surface',\n",
    "                            'Lighting',\n",
    "                            'Pedestrian_Involved',\n",
    "                            'Bicycle_Involved',\n",
    "                            'Alcohol_Involved',\n",
    "                            'Motorcycle_Involved',\n",
    "                            'Data_Source',\n",
    "                            'POINT_X',\n",
    "                            'POINT_Y',\n",
    "                            'SHAPE@']:\n",
    "        # remove everything else\n",
    "        fieldMappings.removeFieldMap(fieldMappings.findFieldMapIndex(field.name)) \n",
    "    \n",
    "# Use Merge tool to move features into single dataset\n",
    "arcpy.management.Merge([caCrash, nvCrash], tahoeCrash, fieldMappings)\n",
    "print(\"Crash Feature Classes Merged\")\n",
    "\n",
    "# ## Spatial Join of Corridor IDs\n",
    "# in memory points to be used for spatial join results\n",
    "corridorPoints = memory + 'CrashPoint_Corridor'\n",
    "# Spatial Join\n",
    "arcpy.SpatialJoin_analysis(tahoeCrash, corridor, corridorPoints, \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "\n",
    "# use function to transfer spatial join results to crash stagin layer\n",
    "fieldJoinCalc(tahoeCrash, ['OBJECTID', 'Corridor_ID'], corridorPoints, ['OBJECTID','CORRIDOR_NAME'])\n",
    "print(\"Finished updating staging layer\")\n",
    "\n",
    "\n",
    "tempLayer = \"deleteLayers\"\n",
    "\n",
    "# Run MakeFeatureLayer\n",
    "arcpy.management.MakeFeatureLayer(tahoeCrash, tempLayer)\n",
    " \n",
    "arcpy.management.SelectLayerByLocation(tempLayer, \"have_their_center_in\", \n",
    "                                       trpa,\n",
    "                                       search_distance=\"\", \n",
    "                                       selection_type=\"NEW_SELECTION\", \n",
    "                                       invert_spatial_relationship=\"INVERT\")\n",
    " \n",
    "# Run GetCount and if some features have been selected, then \n",
    "#  run DeleteFeatures to remove the selected features.\n",
    "if int(arcpy.management.GetCount(tempLayer)[0]) > 0:\n",
    "    arcpy.management.DeleteFeatures(tempLayer)\n",
    "print(\"features deleted\")\n",
    "\n",
    "# outfc = \n",
    "# Update SDE - Truncate Append\n",
    "# updateSDE(tahoeCrash, outfc, fieldnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NV 2021 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from arcgis import GeoAccessor\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = \"F:/GIS/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/2021 Crash Data/NV/Statewide Data 2021.gdb\"\n",
    "\n",
    "raw_crash_featureclass = \"Crash_Data_2021\"\n",
    "person_table = \"Person_Table_2021\"\n",
    "vehicle_table = \"Vehicle_Table_2021\"\n",
    "updated_crash_featureclass = 'Crash_Data_2021_Updated'\n",
    "\n",
    "\n",
    "# Create a new feature class based on the existing one\n",
    "arcpy.management.CopyFeatures(raw_crash_featureclass, updated_crash_featureclass)\n",
    "\n",
    "# Add x and y fields to the new feature class\n",
    "arcpy.management.AddField(updated_crash_featureclass, 'POINT_X', 'DOUBLE')\n",
    "arcpy.management.AddField(updated_crash_featureclass, 'POINT_Y', 'DOUBLE')\n",
    "\n",
    "# Use an UpdateCursor to calculate x and y coordinates\n",
    "with arcpy.da.UpdateCursor(updated_crash_featureclass, ['SHAPE@X', 'SHAPE@Y', 'POINT_X', 'POINT_Y']) as cursor:\n",
    "    for row in cursor:\n",
    "        x, y = row[0], row[1]\n",
    "        row[2] = x\n",
    "        row[3] = y\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "def import_table_from_fgb(tablename):\n",
    "    data = []\n",
    "\n",
    "    # Use SearchCursor to iterate through the feature class\n",
    "    fields = [field.name for field in arcpy.ListFields(tablename)]\n",
    "    with arcpy.da.SearchCursor(tablename, fields) as cursor:\n",
    "        for row in cursor:\n",
    "            data.append(row)\n",
    "    # Convert the list of tuples to a Pandas DataFrame\n",
    "    df = pd.DataFrame(data, columns=fields)\n",
    "    return df\n",
    "def renamecolumns(df, column_mapping):\n",
    "    df = df.rename(columns=column_mapping).drop(columns=[col for col in df.columns if col not in column_mapping])\n",
    "    return df\n",
    "\n",
    "\n",
    "person_df = import_table_from_fgb(person_table)\n",
    "vehicle_df = import_table_from_fgb(vehicle_table)\n",
    "\n",
    "crash_sdf = GeoAccessor.from_featureclass(updated_crash_featureclass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map and rename columns for dfs from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_column_mapping = {\n",
    "   'CrashDate' : 'Date',\n",
    "'CrashTime' : 'Time',\n",
    "'Weather' : 'Weather_1',\n",
    "'NumFatalities' : 'Num_Killed',\n",
    "'NumInjured' : 'Num_Injured',\n",
    "'VehCrashType' : 'Crash_Type',\n",
    "'NumVehicles' : 'Num_Vehicles',\n",
    "'RoadSurface' : 'Road_Surface',\n",
    "'LightCondition' : 'Lighting',\n",
    "'PedestrianInvolved' : 'Pedestrian_Involved',\n",
    "'CrashNum' : 'NV_Accident_Num',\n",
    "'CrashSeverity': 'Crash_Severity',\n",
    "'aNo' : 'NV_Accident_Rec_Num',\n",
    "'County' : 'County',\n",
    "'RoadEnvironmentalFactors':'Road_Condition_1',\n",
    "'SHAPE':'SHAPE',\n",
    "'POINT_X':'POINT_X',\n",
    "'POINT_Y':'POINT_Y'\n",
    "}\n",
    "\n",
    "crash_sdf_clean = renamecolumns(crash_sdf,crash_column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Lookup Lists\n",
    "def import_lookup_dictionary(lookup_csv, key_column, value_column, filter_column, filter_condition):\n",
    "    df = pd.read_csv(lookup_csv)\n",
    "    filtered_df = df[df[filter_column] == filter_condition]\n",
    "    dictionary = filtered_df.set_index(key_column)[value_column].to_dict()\n",
    "    return dictionary\n",
    "def update_if_contains(df, column_to_update, lookup_dictionary):\n",
    "    for key, value in lookup_dictionary.items():\n",
    "        df.loc[df[column_to_update].str.contains(key), column_to_update] = value\n",
    "    return df\n",
    "\n",
    "crash_type_lookup_nv = import_lookup_dictionary('LookupLists/CrashType_Lookup.csv','Crash Type', 'Crash_Type', 'State', 'NV')\n",
    "lighting_lookup_nv = import_lookup_dictionary('LookupLists/Lighting_Lookup.csv','Lighting_Raw', 'Lighting_Update', 'State', 'NV')\n",
    "road_conditions_lookup_nv  = import_lookup_dictionary('LookupLists/RoadConditions_Lookup.csv','HWY Factors', 'Road_Condition_1', 'State', 'NV')\n",
    "road_surface_lookup_nv = import_lookup_dictionary('LookupLists/RoadSurface_Lookup.csv','Factors Roadway', 'Road_Surface', 'State', 'NV')\n",
    "weather_lookup_nv = import_lookup_dictionary('LookupLists/Weather_Lookup.csv','Weather_Raw', 'Weather', 'State', 'NV')\n",
    "crash_lookup_nv = import_lookup_dictionary('LookupLists/CrashSeverity_Lookup.csv','CrashSeverity', 'Crash_Severity', 'State', 'NV')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crash_sdf_clean['Lighting'] = crash_sdf_clean['Lighting'].replace(lighting_lookup_nv, value=\"Not stated\")\n",
    "#crash_sdf_clean['Road_Condition_2']= crash_sdf_clean['Road_Condition_1']\n",
    "crash_sdf_clean = update_if_contains(crash_sdf_clean,'Road_Condition_1',road_conditions_lookup_nv)\n",
    "#Not really sure what's going on with this field - road surface in Raw data is Asphalt etc but road surface in crash data is dry, wet etc\n",
    "crash_sdf_clean['Road_Surface'] = crash_sdf_clean['Road_Condition_1']\n",
    "crash_sdf_clean =update_if_contains(crash_sdf_clean,'Weather_1', weather_lookup_nv)\n",
    "crash_sdf_clean['Crash_Severity']=crash_sdf_clean['Crash_Severity'].map(crash_lookup_nv)\n",
    "crash_sdf_clean['Lighting']=crash_sdf_clean['Lighting'].map(lighting_lookup_nv)\n",
    "crash_sdf_clean['Time']=crash_sdf_clean['Time'].str.slice(0,2) + ':' + crash_sdf_clean['Time'].str.slice(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use person dataframe to get number of bike involved, pedestrian, alcohol status\n",
    "def type_involved(df_slice, types, type_column):\n",
    "    if (df_slice[type_column].isin(types)).any():\n",
    "        return 'Y'\n",
    "    else:\n",
    "        return 'N'\n",
    "    \n",
    "def alcohol_involved(df_slice, substring):\n",
    "    # Check if the substring is contained anywhere in 'Value2'\n",
    "    if ((df_slice['AlcDrugInvolved'].str.contains(substring)) & (df_slice['PersonType']=='Driver')).any():\n",
    "        return 'Y'  \n",
    "    else: \n",
    "        return 'N'\n",
    "\n",
    "def conditional_count(df_slice, condition_column1, types1, condition_column2, types2):\n",
    "    # Count the number of records meeting a specific condition\n",
    "    return ((df_slice[condition_column1].isin(types1)) & (df_slice[condition_column2].isin(types2))).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_columns_to_keep = ['vcNo', 'VehType']\n",
    "vehicle_df_simple = vehicle_df[vehicle_columns_to_keep]\n",
    "person_df_wt_vehicle = pd.merge(person_df,vehicle_df_simple,how='left',left_on='vcNoRelated',right_on='vcNo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ped_types= ['Skater','Pedestrian','Other Non-Motorist','Wheelchair']\n",
    "mortality_codes = ['K']\n",
    "injury_codes = ['C', 'B', 'A']\n",
    "bike_types = ['Pedal Cyclist', 'E-Bike', 'Other Cyclist']\n",
    "motorcycle_types = ['MC - MOTORCYCLE',\t'MD - MOPED',\t'MOPED',\t'MOTORBIKE',\t'MOTORCYCLE',\t'MOTORSCOOTER',\t'MT - MOTORCYCLE',\t'OTHER']\n",
    "\n",
    "person_grouped = person_df_wt_vehicle.groupby('CrashNum').apply(lambda group_df: pd.Series({\n",
    "    'Num_Ped_Killed': conditional_count(group_df, condition_column1='PersonType',types1=ped_types,condition_column2='InjuryCode',types2=mortality_codes),\n",
    "    'Num_Ped_Injured': conditional_count(group_df, condition_column1='PersonType',types1=ped_types,condition_column2='InjuryCode',types2=injury_codes),\n",
    "    'Num_Bicyclist_Killed': conditional_count(group_df, condition_column1='PersonType',types1=bike_types,condition_column2='InjuryCode',types2=mortality_codes),\n",
    "    'Num_Bicyclist_Injured': conditional_count(group_df, condition_column1='PersonType',types1=bike_types,condition_column2='InjuryCode',types2=injury_codes),\n",
    "    'Num_Motorcyclist_Killed': conditional_count(group_df, condition_column1='VehType',types1=motorcycle_types,condition_column2='InjuryCode',types2=mortality_codes),\n",
    "    'Num_Motorcyclist_Injured': conditional_count(group_df, condition_column1='VehType',types1=motorcycle_types,condition_column2='InjuryCode',types2=injury_codes),\n",
    "    'Bicycle_Involved': type_involved(group_df,bike_types,'PersonType'),\n",
    "    'Motorcycle_Involved': type_involved(group_df,motorcycle_types,'VehType'),\n",
    "    'Alcohol_Involved': alcohol_involved(group_df, 'ALCO'),\n",
    "})).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create final dataframe for NV 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevada_crashes_2021=pd.merge(crash_sdf_clean, person_grouped, how='left',left_on='NV_Accident_Num',right_on='CrashNum')\n",
    "#Fill in hard coded fields\n",
    "nevada_crashes_2021['Violation']  = \"N/A\"\n",
    "nevada_crashes_2021['Hit_and_Run'] = \"N/A\"\n",
    "nevada_crashes_2021['Motor_Vehicle_Interacted_With'] = \"N/A\"\n",
    "nevada_crashes_2021['Pedestrian_Action'] = \"N/A\"\n",
    "nevada_crashes_2021['Year']  = \"2021\"\n",
    "nevada_crashes_2021['Data_Source'] = \"NDOT\"\n",
    "nevada_crashes_2021['CA_Case_ID'] = np.nan\n",
    "nevada_crashes_2021['City'] = np.nan\n",
    "nevada_crashes_2021['Num_Parties'] = np.nan\n",
    "nevada_crashes_2021['Corridor_ID'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nevada_crashes_2021.to_excel('datatest.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = \"F:/gis/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/\"\n",
    "\n",
    "# setup environment variables\n",
    "arcpy.env.overwriteOutput = True\n",
    "#arcpy.env.workspace = \"//Trpa-fs01/GIS/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/CrashData/CrashData.gdb\"\n",
    "arcpy.env.workspace = \"F:/GIS/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/CrashData/CrashData.gdb\"\n",
    "\n",
    "# create a spatial reference object for the output coordinate system \n",
    "# output projection for data going into SDE should be UTM Zone 10N (EPSG: 26910)\n",
    "out_coordinate_system = arcpy.SpatialReference(26910)\n",
    "\n",
    "# network path to connection files\n",
    "#filePath = \"//Trpa-fs01/GIS/DB_CONNECT\"\n",
    "filePath = \"F:/GIS/DB_CONNECT\"\n",
    "\n",
    "# database file path \n",
    "sdeBase  = os.path.join(filePath, \"Vector.sde\")\n",
    "\n",
    "# SDE feature classes needed for spatial joins\n",
    "corridor = os.path.join(sdeBase, 'sde.SDE.Transportation\\sde.SDE.Corridor')\n",
    "trpa     = os.path.join(sdeBase, 'sde.SDE.Jurisdictions\\sde.SDE.TRPA_bdy')\n",
    "# # in memory files\n",
    "memory = \"memory\" + \"\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, December 18, 2023 3:30:15 PM\",\"Succeeded at Monday, December 18, 2023 3:30:47 PM (Elapsed Time: 32.37 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'F:/GIS/PROJECTS/ResearchAnalysis/Monitoring/Data/Crash/CrashData/CrashData.gdb\\\\NV_Crash_2021_Project'>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# export dataframe to csv \n",
    "nevada_crashes_2021.to_csv(os.path.join(workspace, \"NV_Crash_2021.csv\" ))\n",
    "# get NV CSV for XY Table TO Point\n",
    "nvCSV = os.path.join(workspace, \"NV_Crash_2021.csv\" )\n",
    "\n",
    "# name the output feature class\n",
    "nvFC  = 'NV_Crash_2021'\n",
    "\n",
    "\n",
    "\n",
    "# Nevada data frame to feature class \n",
    "# input data is in NAD 1983 UTM Zone 11N coordinate system\n",
    "arcpy.management.XYTableToPoint(nvCSV, nvFC, \n",
    "                                x_coords, y_coords, \"\",\n",
    "                                # set prjoection transform to from\n",
    "                                arcpy.SpatialReference(26911))\n",
    "# output data for project tool\n",
    "output_NV_Crash_Project = \"NV_Crash_2021_Project\"\n",
    "\n",
    "# project from UTM to WGS\n",
    "arcpy.Project_management(nvFC, output_NV_Crash_Project, out_coordinate_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fieldJoinCalc(updateFC, updateFieldsList, sourceFC, sourceFieldsList):\n",
    "    from time import strftime  \n",
    "    print (\"Started data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#     log.info(\"Started data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    # Use list comprehension to build a dictionary from arcpy SearchCursor  \n",
    "    valueDict = {r[0]:(r[1:]) for r in arcpy.da.SearchCursor(sourceFC, sourceFieldsList)}  \n",
    "   \n",
    "    with arcpy.da.UpdateCursor(updateFC, updateFieldsList) as updateRows:  \n",
    "        for updateRow in updateRows:  \n",
    "            # store the Join value of the row being updated in a keyValue variable  \n",
    "            keyValue = updateRow[0]  \n",
    "            # verify that the keyValue is in the Dictionary  \n",
    "            if keyValue in valueDict:  \n",
    "                # transfer the value stored under the keyValue from the dictionary to the updated field.  \n",
    "                updateRow[1] = valueDict[keyValue][0]  \n",
    "                updateRows.updateRow(updateRow)    \n",
    "    del valueDict  \n",
    "    print (\"Finished data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "#     log.info(\"Finished data transfer: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started data transfer: 2023-12-18 15:32:02\n",
      "Finished data transfer: 2023-12-18 15:32:06\n",
      "Finished updating staging layer\n",
      "features deleted\n"
     ]
    }
   ],
   "source": [
    "# ## Spatial Join of Corridor IDs\n",
    "# in memory points to be used for spatial join results\n",
    "corridorPoints = memory + 'CrashPoint_Corridor'\n",
    "# Spatial Join\n",
    "tahoeCrash = \"NV_Crash_2021_Project\"\n",
    "\n",
    "arcpy.SpatialJoin_analysis(tahoeCrash, corridor, corridorPoints, \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "\n",
    "# use function to transfer spatial join results to crash stagin layer\n",
    "fieldJoinCalc(tahoeCrash, ['OBJECTID', 'Corridor_ID'], corridorPoints, ['OBJECTID','CORRIDOR_NAME'])\n",
    "print(\"Finished updating staging layer\")\n",
    "\n",
    "\n",
    "tempLayer = \"deleteLayers\"\n",
    "\n",
    "# Run MakeFeatureLayer\n",
    "arcpy.management.MakeFeatureLayer(tahoeCrash, tempLayer)\n",
    " \n",
    "arcpy.management.SelectLayerByLocation(tempLayer, \"have_their_center_in\", \n",
    "                                       trpa,\n",
    "                                       search_distance=\"\", \n",
    "                                       selection_type=\"NEW_SELECTION\", \n",
    "                                       invert_spatial_relationship=\"INVERT\")\n",
    " \n",
    "# Run GetCount and if some features have been selected, then \n",
    "#  run DeleteFeatures to remove the selected features.\n",
    "if int(arcpy.management.GetCount(tempLayer)[0]) > 0:\n",
    "    arcpy.management.DeleteFeatures(tempLayer)\n",
    "print(\"features deleted\")\n",
    "\n",
    "# outfc = \n",
    "# Update SDE - Truncate Append\n",
    "# updateSDE(tahoeCrash, outfc, fieldnames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
