{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_43764\\4038197288.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['year'] = filtered_df[timestamp_col].dt.year\n",
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_43764\\4038197288.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['month'] = filtered_df[timestamp_col].dt.month\n",
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_43764\\4038197288.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['day_of_week'] = filtered_df[timestamp_col].dt.day_name()\n",
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_43764\\4038197288.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['year'] = filtered_df[timestamp_col].dt.year\n",
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_43764\\4038197288.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['month'] = filtered_df[timestamp_col].dt.month\n",
      "C:\\Users\\amcclary\\AppData\\Local\\Temp\\ipykernel_43764\\4038197288.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['day_of_week'] = filtered_df[timestamp_col].dt.day_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Station  year  month day_of_week  average_flow  observed_days  \\\n",
      "1        308511  2020      1      Monday   3918.333333              3   \n",
      "5        308511  2020      1     Tuesday   2922.000000              2   \n",
      "6        308511  2020      1   Wednesday   8571.000000              1   \n",
      "4        308511  2020      1    Thursday   7928.000000              1   \n",
      "0        308511  2020      1      Friday   9210.000000              2   \n",
      "...         ...   ...    ...         ...           ...            ...   \n",
      "374170  3900024  2024      2   Wednesday   9477.000000              1   \n",
      "374168  3900024  2024      2    Thursday   9412.000000              2   \n",
      "374164  3900024  2024      2      Friday  16971.000000              2   \n",
      "374166  3900024  2024      2    Saturday   5671.500000              2   \n",
      "374167  3900024  2024      2      Sunday   8088.000000              1   \n",
      "\n",
      "        confidence_level  \n",
      "1                     75  \n",
      "5                     75  \n",
      "6                     75  \n",
      "4                     75  \n",
      "0                     75  \n",
      "...                  ...  \n",
      "374170                25  \n",
      "374168                25  \n",
      "374164                25  \n",
      "374166                25  \n",
      "374167                25  \n",
      "\n",
      "[721834 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to read a .gz file and return a DataFrame\n",
    "def read_gz_to_dataframe(file_path, columnnames=None):\n",
    "    with gzip.open(file_path, 'rt') as f:\n",
    "        df = pd.read_csv(f, header=None, names=columnnames)\n",
    "    return df\n",
    "\n",
    "# Function to load and concatenate all .gz files in a folder\n",
    "def load_and_concatenate_files(folder_path, column_names=None):\n",
    "    dataframes = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('.gz'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            df = read_gz_to_dataframe(file_path, column_names)\n",
    "            dataframes.append(df)\n",
    "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "\n",
    "# Function to filter data and produce the summary table\n",
    "def summarize_flow(df, confidence_level, timestamp_col, percent_observed_col, total_flow_col):\n",
    "    # Ensure the timestamp is a datetime object\n",
    "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
    "    \n",
    "    # Filter the DataFrame by the specified confidence level\n",
    "    filtered_df = df[df[percent_observed_col] >= confidence_level]\n",
    "    \n",
    "    # Add columns for the year, month, and day of the week\n",
    "    filtered_df['year'] = filtered_df[timestamp_col].dt.year\n",
    "    filtered_df['month'] = filtered_df[timestamp_col].dt.month\n",
    "    filtered_df['day_of_week'] = filtered_df[timestamp_col].dt.day_name()\n",
    "    \n",
    "    # Group by the station, year, month, and day of the week\n",
    "    summary = filtered_df.groupby(['Station', 'year', 'month', 'day_of_week']).agg(\n",
    "        average_flow=(total_flow_col, 'mean'),\n",
    "        observed_days=(timestamp_col, 'nunique')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Sort by station, year, month, and day of the week\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    summary['day_of_week'] = pd.Categorical(summary['day_of_week'], categories=day_order, ordered=True)\n",
    "    summary = summary.sort_values(['Station', 'year', 'month', 'day_of_week'])\n",
    "    summary['confidence_level'] = confidence_level\n",
    "    \n",
    "    return summary\n",
    "# Example usage\n",
    "columnnames = ['Timestamp',\t'Station',\t'District',\t'Route',\t'Direction of Travel',\t'Lane Type',\t'Station Length',\t'Samples',\t'Percent_Observed',\t'total_flow',\t'Delay (V_t=35)',\t'Delay (V_t=40)',\t'Delay (V_t=45)',\t'Delay (V_t=50)',\t'Delay (V_t=55)',\t'Delay (V_t=60)']\n",
    "folder_path = r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\Daily_Counts'\n",
    "df = load_and_concatenate_files(folder_path, columnnames)\n",
    "\n",
    "# Specify the column names and confidence level\n",
    "timestamp_col = 'Timestamp'\n",
    "percent_observed_col = 'Percent_Observed'\n",
    "total_flow_col = 'total_flow'\n",
    "confidence_level_75 = 75\n",
    "confidence_level_25 = 25\n",
    "# Produce the summary table\n",
    "summary_table_75 = summarize_flow(df, confidence_level_75, timestamp_col, percent_observed_col, total_flow_col)\n",
    "summary_table_25 = summarize_flow(df, confidence_level_25, timestamp_col, percent_observed_col, total_flow_col)\n",
    "# Display the summary table\n",
    "summary_table = pd.concat([summary_table_75, summary_table_25])\n",
    "print(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table.to_csv(r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\summary_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_metadata = pd.read_csv(r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\d03_text_meta_2024_06_04.txt', sep='\\t')\n",
    "station_metadata.to_csv(r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\station_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pems_geodatabase = r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\PEMS_Locations.gdb'\n",
    "#make a feature class from the station metadata\n",
    "import arcpy\n",
    "arcpy.env.workspace = pems_geodatabase\n",
    "arcpy.management.XYTableToPoint(r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\station_metadata.csv', 'station_locations', 'Longitude', 'Latitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_day_lookup = pd.read_csv(r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\modelday_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make timestamp column of df into a date column with just date\n",
    "df['Date'] = pd.to_datetime(df['Timestamp']).dt.date\n",
    "model_day_lookup['date'] = pd.to_datetime(model_day_lookup['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_flow_col = 'total_flow'\n",
    "df_model_days = pd.merge(df, model_day_lookup, left_on='Date', right_on='date', how='inner')\n",
    "percent_observed_col = 'Percent_Observed'\n",
    "total_flow_col = 'total_flow'\n",
    "confidence_level_75 = 75\n",
    "# Filter the DataFrame by the specified confidence level\n",
    "df_model_days = df_model_days[df_model_days[percent_observed_col] >= confidence_level_75]\n",
    "df_model_days =df_model_days[df_model_days['modelday'] == 'yes']\n",
    "df_model_days = df_model_days.drop(columns=['date', 'modelday'])\n",
    "df_model_days['year'] = df_model_days['Timestamp'].dt.year\n",
    "df_model_days_grouped = df_model_days.groupby(['Station', 'year']).agg(average_flow=(total_flow_col, 'mean'),\n",
    "        observed_days=(timestamp_col, 'nunique')\n",
    "    ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_days_grouped.to_csv(r'F:\\Research and Analysis\\Transportation\\TrafficCounts\\PEMS\\model_day_average_flow_75.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
