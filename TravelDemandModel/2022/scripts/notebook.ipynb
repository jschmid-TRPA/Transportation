{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import arcpy\n",
    "from utils import *\n",
    "import numpy as np\n",
    "\n",
    "# pandas options\n",
    "pd.options.mode.copy_on_write = True\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working directory\n",
    "local_path = pathlib.Path().absolute()\n",
    "# set data path as a subfolder of the current working directory TravelDemandModel\\2022\\data\\\n",
    "data_dir = local_path.parents[0] / 'data/raw_data'\n",
    "\n",
    "out_dir  = local_path.parents[0] / 'data/processed_data'\n",
    "# set workspace\n",
    "arcpy.env.workspace = os.path.join(local_path, 'Workspace.gdb')\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "# Set the extent environment using a feature class\n",
    "arcpy.env.extent = \"Tahoe_OccupancyRate_Zones\"\n",
    "# setup in momory workspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "\n",
    "# schema for the final output\n",
    "final_schema = ['APN', 'Residential_Units', 'TouristAccommodation_Units', 'CommercialFloorArea_SqFt',\n",
    "                'RoomsRented_PerDay', 'Lodging_Occupancy_Rate', 'PrimaryResidence_Rate', 'SecondaryResidence_Rate',\n",
    "                'HighIncome_Rate',\t'MediumIncome_Rate', 'LowIncome_Rate', 'PersonsPerUnit',\n",
    "                'TAU_TYPE', 'VHR', 'BLOCK_GROUP', 'TAZ', 'OCCUPANCY_ZONE', \n",
    "                'JURISDICTION', 'COUNTY', 'OWNERSHIP_TYPE','EXISTING_LANDUSE', 'WITHIN_TRPA_BNDY', \n",
    "                'PARCEL_ACRES', 'PARCEL_SQFT', 'SHAPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)\n",
    "#set spatial reference\n",
    "sdf_taz.spatial.sr = sr\n",
    "\n",
    "# Get Unit Data\n",
    "units_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_units = get_fs_data_spatial_query(units_url, \"Year = 2022\")\n",
    "sdf_units.spatial.sr = sr\n",
    "\n",
    "# Get Block Group Data\n",
    "block_groups_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/27'\n",
    "sdf_block = get_fs_data_spatial(block_groups_url)\n",
    "sdf_block = sdf_block.loc[(sdf_block['YEAR'] == 2020) & (sdf_block['GEOGRAPHY'] == 'Block Group')]\n",
    "sdf_block.spatial.sr = sr\n",
    "\n",
    "# Get VHR Data\n",
    "vhr_url = 'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\n",
    "sdf_vhr = get_fs_data_spatial(vhr_url)\n",
    "sdf_vhr.spatial.sr = sr\n",
    "# filter vhr layer to active status\n",
    "sdf_vhr = sdf_vhr.loc[sdf_vhr['Status'] == 'Active']\n",
    "\n",
    "census_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "df_census = get_fs_data(census_url)\n",
    "df_census_2022 = df_census.loc[(df_census['year_sample'] == 2022) & (df_census['sample_level'] == 'block group')]\n",
    "\n",
    "# Get the data - should be 18 campgrounds\n",
    "campground_url = 'https://maps.trpa.org/server/rest/services/Recreation/MapServer/1'\n",
    "sdf_campground =  get_fs_data_spatial_query(campground_url, \"RECREATION_TYPE='Campground'\")\n",
    "\n",
    "# campground occupancy rate data\n",
    "dfCamp = pd.read_csv(os.path.join(data_dir,'Campground_Visitation.csv'))\n",
    "dfCamp_2022 = dfCamp.loc[dfCamp['Year'] == 2022]\n",
    "\n",
    "# occupancy feature class as a spatial dataframe\n",
    "sdf_occ = pd.DataFrame.spatial.from_featureclass(\"Tahoe_OccupancyRate_Zones\")\n",
    "sdf_occ.spatial.sr = sr\n",
    "\n",
    "# get table from geodatabase\n",
    "# occupancy_rate = pd.DataFrame.spatial.from_table(\"OccupancyRates\")\n",
    "occupancy_rate = pd.read_csv(os.path.join(data_dir, 'Occupancy_Rate_Export_JS.csv'))\n",
    "\n",
    "# Get School Enrollment data\n",
    "school_url_table     = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/32'\n",
    "df_school_enrollment = get_fs_data(school_url_table)\n",
    "\n",
    "# Get School Enrollment data - spatial\n",
    "school_url_spatial    = 'https://maps.trpa.org/server/rest/services/Datadownloader_PlanningandJurisdictions/MapServer/14'\n",
    "sdf_school            =  get_fs_data_spatial(school_url_spatial)\n",
    "sdf_school.spatial.sr = sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Future Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do a spatial join and\n",
    "# map values from the source to the target\n",
    "def spatial_join_map(target, source, join_field,  map_field, target_field):\n",
    "    # spatial join\n",
    "    arcpy.SpatialJoin_analysis(target, source, 'memory\\\\temp', \n",
    "                               'JOIN_ONE_TO_ONE', 'KEEP_ALL','HAVE_THEIR_CENTER_IN')\n",
    "    # get result as a spatial dataframe\n",
    "    join = pd.DataFrame.spatial.from_featureclass('memory\\\\temp')\n",
    "    join.info()\n",
    "    # map values\n",
    "    target[target_field] = target[join_field].map(dict(zip(join[join_field], join[map_field])))\n",
    "    return target\n",
    "\n",
    "# check for duplicates\n",
    "def check_dupes(df, col):\n",
    "    df['is_duplicate'] = df.duplicated(subset=col, keep=False)\n",
    "    df.is_duplicate.value_counts()\n",
    "    df.loc[df['is_duplicate'] == True]\n",
    "    df = df.drop_duplicates(subset=col, keep='first', inplace=True)\n",
    "    return df[df.duplicated([col], keep=False)]\n",
    "\n",
    "# check if field exists in data frame and final_schema and if not add it\n",
    "def check_field(df, fields):\n",
    "    for field in fields:\n",
    "        if field not in df.columns:\n",
    "            df[field] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> general spatial joins and categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join to get TAZ\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_taz, \"Existing_Development_TAZ\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatial join to get Block Group\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_block, \"Existing_Development_BlockGroup\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "# spatail join to get Occupancy Rate Zone\n",
    "arcpy.SpatialJoin_analysis(sdf_units, sdf_occ, \"Existing_Development_OccupancyZone\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")\n",
    "arcpy.SpatialJoin_analysis(sdf_vhr, sdf_block, \"VHR_BlockGroup\",\n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Parcels APN with TAU Types\n",
    "tau_lookup = pd.read_csv('Lookup_Lists/lookup_tau_type.csv')\n",
    "#sro_lookup = pd.read_csv('Lookup_Lists/lookup_sro.csv')\n",
    "\n",
    "# check if fields exist in the dataframes\n",
    "sdfUnits   = check_field(sdf_units, final_schema)\n",
    "\n",
    "# merge parcel 2022 with parcel VHR\n",
    "df = sdfUnits.merge(sdf_vhr, on='APN', how='left', indicator=True)\n",
    "\n",
    "# calculate VHR = Yes if VHR is in the parcel\n",
    "df['VHR'] = 'No'\n",
    "df.loc[df['_merge'] == 'both', 'VHR'] = 'Yes'\n",
    "\n",
    "# setup TAU_Type\n",
    "df['TAU_TYPE'] = 'N/A'\n",
    "\n",
    "# filter parcels so only APNs in the lookup are included\n",
    "dfTAU = df[df['APN'].isin(tau_lookup['APN'])]\n",
    "# get TAU_Type from lookup\n",
    "dfTAU['TAU_TYPE'] = dfTAU['APN'].map(tau_lookup.set_index('APN')['TAU_Type'])\n",
    "\n",
    "# any row with ToursitAccommodation_Units > 0 and TAU_Type is null, set TAU_Type to 'HotelMotel'\n",
    "df.loc[(df['TouristAccommodation_Units'] > 0) & (df['TAU_TYPE']=='N/A'), 'TAU_TYPE'] = 'HotelMotel'\n",
    "# for the rows in df that match rows by APN in dfTAU set TAU_Type to the value in dfTAU\n",
    "df.loc[df['APN'].isin(dfTAU['APN']), 'TAU_TYPE'] = dfTAU['TAU_TYPE']\n",
    "\n",
    "# remove _x from column names\n",
    "df.columns = df.columns.str.replace('_x', '')\n",
    "\n",
    "# get results of spatial joins as spatial dataframes\n",
    "sdf_units_taz   = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_TAZ\", sr=sr)  \n",
    "sdf_units_block = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_BlockGroup\", sr=sr)\n",
    "sdf_units_occ   = pd.DataFrame.spatial.from_featureclass(\"Existing_Development_OccupancyZone\", sr=sr)\n",
    "sdf_vhr_block   = pd.DataFrame.spatial.from_featureclass(\"VHR_BlockGroup\", sr=sr)\n",
    "### add logic to handle VHR=\"Yes\"&JURISDICTION='CSLT' == OCCUPANCY_ZONE = CSLT_All elseif JURISDICTION='CSLT' == OCCUPANCY_ZONE = CSLT_Zone1 etc...\n",
    "\n",
    "# map dictionary to sdf_units dataframe to fill in TAZ and Block Group fields\n",
    "df['TAZ']           = df.APN.map(dict(zip(sdf_units_taz.APN,   sdf_units_taz.TAZ)))\n",
    "df['BLOCK_GROUP']   = df.APN.map(dict(zip(sdf_units_block.APN, sdf_units_block.TRPAID)))\n",
    "df['OCCUPANCY_ZONE']= df.APN.map(dict(zip(sdf_units_occ.APN,   sdf_units_occ.OccupancyRate_ZoneID)))\n",
    "\n",
    "# columns to keep\n",
    "df = df[final_schema]\n",
    "df.info()\n",
    "\n",
    "# export to feature class\n",
    "# df.spatial.to_featureclass(location=os.path.join(arcpy.env.workspace, 'SDF'), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupancy Rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes\n",
    "* get interopolated values weighted after spatial join\n",
    "* merge by apn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get table from geodatabase\n",
    "# occupancy_rate = pd.DataFrame.spatial.from_table(\"OccupancyRates\")\n",
    "occupancy_rate = pd.read_csv(os.path.join(data_dir, 'Occupancy_Rate_Export.csv'))\n",
    "df = occupancy_rate\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Filter Occupancy Rate table to Timeframe and Room Type, Merge with Occupancy Zone Feature Class, and Export to Feature Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOccTAU = dfOut.loc[dfOut['RoomType'] == 'TAU']\n",
    "dfOccVHR = dfOut.loc[dfOut['RoomType'] == 'VHR']\n",
    "\n",
    "# merge occupancy rate data to occupancy zones\n",
    "sdf = pd.merge(sdf_occ, dfOccTAU, left_on='OccupancyRate_ZoneID', right_on='Zone_ID', how='left')\n",
    "# export sdf to feature class\n",
    "sdf.spatial.to_featureclass(location=os.path.join('Workspace.gdb', 'OccupancyRate_Zones_TAU'), overwrite=True)\n",
    "\n",
    "# merge occupancy rate data to occupancy zones\n",
    "sdf = pd.merge(sdf_occ, dfOccVHR, left_on='OccupancyRate_ZoneID', right_on='Zone_ID', how='left')\n",
    "# export sdf to feature class put in memory workspace\n",
    "sdf.spatial.to_featureclass(location=os.path.join('Workspace.gdb', 'OccupancyRate_Zones_VHR'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Join TAU and VHR parcels to respective occupancy rate zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter rows where VHR = Yes\n",
    "dfVHR = df.loc[df['VHR'] == 'Yes']\n",
    "# filter rows where TUA > 0\n",
    "dfTAU = df.loc[df['TouristAccommodation_Units'] > 0]\n",
    "\n",
    "# spatial join VHR to occupancy rate zones with VHR values\n",
    "spjoin_vhr = arcpy.analysis.SpatialJoin(dfVHR, \"OccupancyRate_Zones_VHR\", \"OccupancyRate_Zones_VHR_Parcels\", \n",
    "                                        \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "\n",
    "# spatial join VHR to occupancy rate zones with VHR values\n",
    "spjoin_tau = arcpy.analysis.SpatialJoin(dfTAU, \"OccupancyRate_Zones_TAU\", \"OccupancyRate_Zones_TAU_Parcels\", \n",
    "                                        \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "\n",
    "# feature to point in memmory\n",
    "vhr_points = arcpy.management.FeatureToPoint(\"OccupancyRate_Zones_VHR_Parcels\", r\"memory/vhr_points\", \"INSIDE\")\n",
    "tau_points = arcpy.management.FeatureToPoint(\"OccupancyRate_Zones_TAU_Parcels\", r\"memory/tau_points\", \"INSIDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fill in parcel level missing occupancy rates with interpolated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join occupancy rate polygons to parcels with missing values\n",
    "# first i need to fill in the known occupancy rate values\n",
    "# then get parcels with a vhr or tau and fill in with missing values\n",
    "# or should i fill in the zone data with interpolated values...?\n",
    "# get parcels with missing values\n",
    "vhr_missing_occ = dfVHR.loc[dfVHR['OCCUPANCY_ZONE'].isnull()]\n",
    "tau_missing_occ = dfTAU.loc[dfTAU['OCCUPANCY_ZONE'].isnull()]\n",
    "\n",
    "# spatial join VHR to occupancy rate interpolation polygons\n",
    "spjoin_vhr_missing = arcpy.analysis.SpatialJoin(sdf_units_2022_vhr_missing, \"vhr_occupancy_rate_poly\", \"OccupancyRate_Zones_VHR_Parcels_Missing\", \n",
    "                                        \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "# spatial join TAU to occupancy rate interpolation polygons\n",
    "spjoin_tau_missing = arcpy.analysis.SpatialJoin(sdf_units_2022_tau_missing, \"tau_occupancy_rate_poly\", \"OccupancyRate_Zones_TAU_Parcels_Missing\", \n",
    "                                        \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "\n",
    "# merge to original data\n",
    "sdf_units_2022_vhr = pd.concat([spjoin_vhr, spjoin_vhr_missing])\n",
    "sdf_units_2022_tau = pd.concat([spjoin_tau, spjoin_tau_missing])\n",
    "\n",
    "# fill in missing report_occ_rate values\n",
    "sdf_units_2022_vhr['report_occ_rate_x'] = sdf_units_2022_vhr['report_occ_rate_y']\n",
    "sdf_units_2022_tau['report_occ_rate_x'] = sdf_units_2022_tau['report_occ_rate_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['APN', 'Residential_Units', 'TouristAccommodation_Units',\n",
    "                    'CommercialFloorArea_SqFt', 'YEAR',\n",
    "                    'JURISDICTION', 'COUNTY', 'OWNERSHIP_TYPE',\n",
    "                    'EXISTING_LANDUSE', 'TAZ', 'TAU_Type','VHR',\n",
    "                    'WITHIN_TRPA_BNDY', 'PARCEL_ACRES', 'PARCEL_SQFT', 'SHAPE',\n",
    "                    'report_occ_rate_x']\n",
    "\n",
    "# remove _x from column names\n",
    "sdf_units_2022_vhr.columns = sdf_units_2022_vhr.columns.str.replace('_x', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the occupancy rate featuer class as spatial dataframe\n",
    "sdf_occ_rate_tau = pd.DataFrame.spatial.from_featureclass(\"OccupancyRate_Zones_TAU_Parcels\")\n",
    "# get the occupancy rate featuer class as spatial dataframe\n",
    "sdf_occ_rate_vhr = pd.DataFrame.spatial.from_featureclass(\"OccupancyRate_Zones_VHR_Parcels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter sdf_units_2022 to rows where TAU is null or 0\n",
    "sdf_units_2022_no_tau = sdf_occ_rate_tau.loc[(sdf_occ_rate_tau['report_occ_rate'] == 0)|(sdf_occ_rate_tau['report_occ_rate'].isnull())]\n",
    "\n",
    "# filter sdf_units_2022 to rows where VHR is null or 0\n",
    "sdf_units_2022_no_vhr = sdf_occ_rate_vhr.loc[(sdf_occ_rate_vhr['VHR'] == 'Yes')&(sdf_occ_rate_vhr['report_occ_rate'] == 0)|(sdf_occ_rate_vhr['report_occ_rate'].isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join to occupancy rate raster\n",
    "sdf_units_2022_no_tau = pd.DataFrame.spatial.from_featureclass(\"OccupancyRate_Zones_TAU_Parcels\")\n",
    "sdf_units_2022_no_vhr = pd.DataFrame.spatial.from_featureclass(\"OccupancyRate_Zones_VHR_Parcels\")\n",
    "\n",
    "# merge occupancy rate data to occupancy zones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generate Spatial Interpolated Occupancy Rate Surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the extent environment using a feature class\n",
    "arcpy.env.extent = \"OccupancyRate_Zones_TAU\"\n",
    "\n",
    "# make feature layer from in memory points\n",
    "arcpy.management.MakeFeatureLayer(\"in_memory/vhr_points\", \"vhr_points_lyr\")\n",
    "arcpy.management.MakeFeatureLayer(\"in_memory/tau_points\", \"tau_points_lyr\")\n",
    "# filter out rows where occupancy rate is null or 0\n",
    "arcpy.management.SelectLayerByAttribute(\"vhr_points_lyr\", \"NEW_SELECTION\", \"report_occ_rate IS NOT NULL OR report_occ_rate > 0\")\n",
    "arcpy.management.SelectLayerByAttribute(\"tau_points_lyr\", \"NEW_SELECTION\", \"report_occ_rate IS NOT NULL OR report_occ_rate > 0\")\n",
    "\n",
    "# set the output cell size\n",
    "cell_size = 30\n",
    "# set the power parameter\n",
    "power = 2\n",
    "# set the search radius\n",
    "search_radius = 10000\n",
    "\n",
    "# set the output raster\n",
    "out_raster = 'tau_occupancy_rate'\n",
    "# run the IDW for TAUs\n",
    "arcpy.sa.Idw(\"tau_points_lyr\", \n",
    "             z_field='report_occ_rate', \n",
    "             cell_size=cell_size, \n",
    "             power=power, \n",
    "             search_radius=search_radius).save(out_raster)\n",
    "\n",
    "# set the output raster\n",
    "out_raster = 'vhr_occupancy_rate'\n",
    "# run the IDW for VHRs\n",
    "arcpy.sa.Idw(\"vhr_points_lyr\", \n",
    "             z_field='report_occ_rate', \n",
    "             cell_size=cell_size, \n",
    "             power=power, \n",
    "             search_radius=search_radius).save(out_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate between \n",
    "arcpy.sa.Sample(\n",
    "    in_rasters=\"tau_occupancy_rate\",\n",
    "    in_location_data=\"OccupancyRate_Zones_TAU_Parcels\",\n",
    "    out_table=\"tau_interpolated_occupancy_rate\",\n",
    "    resampling_type=\"BILINEAR\",\n",
    "    unique_id_field=\"OBJECTID\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    acquisition_definition=None,\n",
    "    statistics_type=\"MEAN\",\n",
    "    percentile_value=None,\n",
    "    buffer_distance=None,\n",
    "    layout=\"ROW_WISE\",\n",
    "    generate_feature_class=\"FEATURE_CLASS\"\n",
    ")\n",
    "# interpolate VHR occupancy rate\n",
    "arcpy.sa.Sample(\n",
    "    in_rasters=\"vhr_occupancy_rate\",\n",
    "    in_location_data=\"OccupancyRate_Zones_VHR_Parcels\",\n",
    "    out_table=\"vhr_interpolated_occupancy_rate\",\n",
    "    resampling_type=\"BILINEAR\",\n",
    "    unique_id_field=\"OBJECTID\",\n",
    "    process_as_multidimensional=\"CURRENT_SLICE\",\n",
    "    acquisition_definition=None,\n",
    "    statistics_type=\"MEAN\",\n",
    "    percentile_value=None,\n",
    "    buffer_distance=None,\n",
    "    layout=\"ROW_WISE\",\n",
    "    generate_feature_class=\"FEATURE_CLASS\"\n",
    ")\n",
    "\n",
    "# spatial join null parcels with raster interpolated values\n",
    "vhr_null = arcpy.management.MakeFeatureLayer(\"OccupancyRate_Zones_VHR_Parcels\", \"vhr_null_lyr\")\n",
    "tau_null = arcpy.management.MakeFeatureLayer(\"OccupancyRate_Zones_TAU_Parcels\", \"tau_null_lyr\")\n",
    "\n",
    "arcpy.management.SelectLayerByAttribute(\"vhr_points_lyr\", \"NEW_SELECTION\", \"report_occ_rate IS NULL OR report_occ_rate = 0\")\n",
    "arcpy.management.SelectLayerByAttribute(\"tau_points_lyr\", \"NEW_SELECTION\", \"report_occ_rate IS NULL OR report_occ_rate = 0\")\n",
    "\n",
    "# spatial join\n",
    "arcpy.analysis.SpatialJoin(\"vhr_null_lyr\", \"vhr_interpolated_occupancy_rate\", \"OccupancyRate_Zones_VHR_Parcels_Null\", \n",
    "                           \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "arcpy.analysis.SpatialJoin(\"tau_null_lyr\", \"tau_interpolated_occupancy_rate\", \"OccupancyRate_Zones_TAU_Parcels_Null\",\n",
    "                            \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "\n",
    "# get spatial enabled dataframes\n",
    "sdf_vhr_null = pd.DataFrame.spatial.from_featureclass(\"OccupancyRate_Zones_VHR_Parcels_Null\")\n",
    "sdf_tau_null = pd.DataFrame.spatial.from_featureclass(\"OccupancyRate_Zones_TAU_Parcels_Null\")\n",
    "\n",
    "# merge null values with original data\n",
    "sdf_vhr_null = pd.merge(sdf_vhr_null, sdf_units_2022_vhr, on='APN', how='left')\n",
    "sdf_tau_null = pd.merge(sdf_tau_null, sdf_units_2022_tau, on='APN', how='left')\n",
    "\n",
    "# set occupancy rate to the interpolated value\n",
    "sdf_vhr_null['Lodging_Occupancy_Rate'] = sdf_vhr_null['MEAN']\n",
    "sdf_tau_null['Lodging_Occupancy_Rate'] = sdf_tau_null['MEAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rows of missing values for report_occ_rate\n",
    "dfTau = pd.DataFrame.spatial.from_featureclass(\"tau_interpolated_occupancy_rate\")\n",
    "dfTau.spatial.sr = sr\n",
    "dfTau = dfTau.loc[dfTau['report_occ_rate'].isnull()]\n",
    "# get rows of missing values for report_occ_rate\n",
    "dfVhr = pd.DataFrame.spatial.from_featureclass(\"vhr_interpolated_occupancy_rate\")\n",
    "dfVhr.spatial.sr = sr\n",
    "dfVhr = dfVhr.loc[dfVhr['report_occ_rate'].isnull()]\n",
    "\n",
    "# spatial join\n",
    "spjoin_tau = arcpy.analysis.SpatialJoin(sdf_units, \"tau_interpolated_occupancy_rate\", \"OccupancyRate_Zones_TAU_Parcels\", \n",
    "                                        \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "spjoin_vhr = arcpy.analysis.SpatialJoin(sdf_units, \"vhr_interpolated_occupancy_rate\", \"OccupancyRate_Zones_VHR_Parcels\",\n",
    "                                        \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", None, \"INTERSECT\", None, None)\n",
    "\n",
    "# move values\n",
    "sdf_units.loc[sdf_units['APN'].isin(spjoin_tau['APN']), 'Lodging_Occupancy_Rate'] = spjoin_tau['report_occ_rate']\n",
    "sdf_units.loc[sdf_units['APN'].isin(spjoin_vhr['APN']), 'Lodging_Occupancy_Rate'] = spjoin_vhr['report_occ_rate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Calculate Weighted Occupance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Washoe County\n",
    "\n",
    "# if the Zone_ID is Washoe County set Report_OccRate to Report_RoomsRented by Report _RoomsAvailable\n",
    "df.loc[df['Zone_ID'] == 'Washoe County', 'Report_OccRate'] = df['Report_RoomsRented']/df['Report_RoomsAvailable']\n",
    "\n",
    "# if the Zone_ID is Washoe County and Temporal_Scale is Quarterly /3 and then add that to the three rows where the Zone_ID is Washoe County and Temporal_Scale is Monthly\n",
    "df['ExtraUnits']   = 0\n",
    "df.loc[(df['Zone_ID'] == 'Washoe County') & (df['Temporal_Scale'] == 'Quarterly'), 'ExtraUnits'] = df['Report_RoomsRented']/3\n",
    "df.loc[(df['Zone_ID'] == 'Washoe County') & (df['Temporal_Scale'] == 'Monthly'), 'Report_RoomsAvailable'] = df['Report_RoomsRented'] + df['ExtraUnits']\n",
    "\n",
    "# drop row where the Zone_ID is Washoe County and Temporal_Scale is Quarterly\n",
    "df = df.loc[~((df['Zone_ID'] == 'Washoe County') & (df['Temporal_Scale'] == 'Quarterly'))]\n",
    "\n",
    "# drop ExtraUnits column\n",
    "df.drop(columns=['ExtraUnits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df\n",
    "df = occupancy_rate\n",
    "\n",
    "# filter to columns \n",
    "columns = ['Zone_ID', 'Period', 'RoomType', 'Report_OccRate','TRPA_OccRate']\n",
    "\n",
    "# dictinary to convert the time frames to make things cleaner\n",
    "timeframe_dict = {\n",
    "    '2022-06-01': 'June',\n",
    "    '2022-08-01': 'August',\n",
    "    '2022-09-01': 'September',\n",
    "    'Q4 21-22'  : 'April-June',\n",
    "    'Q1 22-23'  : 'July-September',\n",
    "    'Q2 2022'   : 'April-June',\n",
    "    'Q3 2022'   : 'July-September'\n",
    "}\n",
    "\n",
    "# Define the weights for each month based on the number of days they contribute\n",
    "weights = {\n",
    "    'June'          : 8/20,\n",
    "    'August'        : 3/20,\n",
    "    'September'     : 9/20,\n",
    "    'April-June'    : 8/20,\n",
    "    'July-September': 12/20\n",
    "}\n",
    "\n",
    "# Period field based on Timeframe and timeframe_dict\n",
    "df['Period'] = df['Timeframe'].map(timeframe_dict)\n",
    "\n",
    "# calculate the weighted occupancy rates\n",
    "for key,value in weights.items():\n",
    "    # Apply weights to the occupancy rates\n",
    "    df.loc[df['Period'] == key, 'TRPA_OccRate'] = df['Report_OccRate'] * value\n",
    "\n",
    "# Calculate RoomsRentedPerDay based on the period\n",
    "df['RoomsRentedPerDay'] = df.apply(lambda row: row['Report_RoomsRented'] / 30 if row['Period'] in ['June', 'September'] else\n",
    "                                   (row['Report_RoomsRented'] / 31 if row['Period'] == 'August' else\n",
    "                                    (row['Report_RoomsRented'] / 91 if row['Period'] == 'April-June' else\n",
    "                                     (row['Report_RoomsRented'] / 92 if row['Period'] == 'July-September' else 0))), axis=1).fillna(0).astype(int)\n",
    "\n",
    "# filter by Temporal_Scale\n",
    "df_monthly   = df.loc[df['Temporal_Scale'] == 'Monthly']\n",
    "df_quarterly = df.loc[df['Temporal_Scale'] == 'Quarterly']\n",
    "\n",
    "# group by for montthly and quarterly and mean for Report_OccRate and sum for TRPA_OccRate\n",
    "dfMonthly   = df_monthly.groupby(['Zone_ID', 'RoomType', 'Temporal_Scale']).agg({'RoomsRentedPerDay': 'mean','Report_RoomsAvailable':'sum',\n",
    "                                                                                 'Report_RoomsRented':'sum', 'Report_OccRate': 'mean', \n",
    "                                                                                 'TRPA_OccRate': 'sum'}).reset_index()\n",
    "\n",
    "dfQuarterly = df_quarterly.groupby(['Zone_ID', 'RoomType', 'Temporal_Scale']).agg({'RoomsRentedPerDay': 'mean','Report_RoomsAvailable':'sum',\n",
    "                                                                                   'Report_RoomsRented':'sum', 'Report_OccRate': 'mean', \n",
    "                                                                                   'TRPA_OccRate': 'sum'}).reset_index()\n",
    "\n",
    "# concat the two dataframe\n",
    "dfOut = pd.concat([dfMonthly, dfQuarterly])\n",
    "\n",
    "# cast RoomsRentedPerDay as int \n",
    "dfOut['RoomsRentedPerDay'] = dfOut['RoomsRentedPerDay'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter RoomType to HotelMoteland Casino\n",
    "df1 = dfOut.loc[dfOut['RoomType'].isin(['VHR'])]\n",
    "df1.RoomsRentedPerDay.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter RoomType to VHR\n",
    "df2 = dfOut.loc[~dfOut['RoomType'].isin(['VHR'])] \n",
    "df2.RoomsRentedPerDay.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Campground Occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge campground data with occupancy rate data on campground name\n",
    "sdf_campground = sdf_campground.merge(dfCamp_2022, left_on='RECREATION_NAME', right_on='Campground', \n",
    "                                      how='left', indicator=True)\n",
    "\n",
    "# keep only columns of interest\n",
    "sdf_campground = sdf_campground[['RECREATION_NAME', 'Occupancy_Rate','SHAPE']]\n",
    "\n",
    "# filter sdf_campground to only campgrounds with occupancy rate data\n",
    "sdf_campground = sdf_campground[sdf_campground['Occupancy_Rate'].notnull()]\n",
    "\n",
    "# IDW to get the occupancy rate for each campground\n",
    "# set the output cell size\n",
    "cell_size = 500\n",
    "# set the power parameter\n",
    "power = 2\n",
    "# set the search radius\n",
    "search_radius = 5000\n",
    "# set the output raster\n",
    "out_raster = 'campground_occupancy_rate'\n",
    "# run the IDW\n",
    "arcpy.sa.Idw(in_features=sdf_campground, \n",
    "             z_field='Occupancy_Rate', \n",
    "             cell_size=cell_size, \n",
    "             power=power, \n",
    "             search_radius=search_radius).save(out_raster)\n",
    "\n",
    "# spatial join to campground points with NaN occupancy rate\n",
    "sdf_campground_nan = sdf_campground[sdf_campground['Occupancy_Rate'].isnull()]\n",
    "# spatial join to campground points with NaN occupancy rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge campground data with occupancy rate data on campground name\n",
    "sdf_campground = sdf_campground.merge(dfCamp_2022, left_on='RECREATION_NAME', right_on='Campground', \n",
    "                                      how='left', indicator=True)\n",
    "\n",
    "# spatial join TAZ data to campground data\n",
    "arcpy.SpatialJoin_analysis(sdf_campground, sdf_taz, 'taz_campground', \n",
    "                           'JOIN_ONE_TO_ONE', 'KEEP_ALL', \n",
    "                           match_option='HAVE_THEIR_CENTER_IN')\n",
    "\n",
    "# read in output of spatial join as sdf\n",
    "sdf_campground_taz = pd.DataFrame.spatial.from_featureclass('taz_campground')\n",
    "\n",
    "# get sites sold by multiplying the number of sites by the occupancy rate\n",
    "sdf_campground_taz['SitesSold'] = sdf_campground_taz['Total_Sites'] * sdf_campground_taz['Occupancy_Rate']\n",
    "\n",
    "# group by TAZ and sum of sites sold within TAZ\n",
    "sdf_campground_taz_grouped = sdf_campground_taz.groupby('TAZ').agg(\n",
    "                                                {'SitesSold': 'sum'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply weighting by model days (same as occupancy zone rate weighting)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overnight Visitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_units.groupby('TAZ','TAU_TYPE').agg({'TouristAccommodation_Units': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAUs 6190 were rented on model day....2,200 VHRs were rented on model day\n",
    "\n",
    "# get the number of occupied units by multiplying the number of units by the occupancy rate\n",
    "\n",
    "# multiply the number of TAUs by the occupancy rate then add up by zone? or by TAZ?\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentHouseSeasonal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Enrollment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Type to Null\n",
    "sdf_school['TYPE'] = None\n",
    "# set SchoolType to 'elementary' if it contains 'elementary' or 'magnet' or 'academy'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('elementary', case=False), 'TYPE'] = 'Elementary School'\n",
    "# set SchoolType to 'middle' if it contains 'middle'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('middle', case=False), 'TYPE'] = 'Middle School'\n",
    "# set SchoolType to 'high' if it contains 'high'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('high', case=False), 'TYPE'] = 'High School'\n",
    "# set SchoolType to 'college' if it contains 'college'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('college', case=False), 'TYPE'] = 'College'\n",
    "# set SchoolType to 'other' if it it does not contain any of the above\n",
    "sdf_school.loc[sdf_school['TYPE'].isnull(), 'TYPE'] = 'Elementary School'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join TAZs to School points\n",
    "sdf_school_taz = sdf_school.spatial.join(sdf_taz, how='inner')\n",
    "# group by TYPE and sum of Enrollment within TAZ \n",
    "sdf_school_taz_grouped = sdf_school_taz.groupby(['TYPE', 'TAZ']).agg(\n",
    "                                                {'ENROLLMENT': 'sum'}).reset_index()\n",
    "# unstack by TYPE as columns and TAZ as a column\n",
    "sdf_school_taz_grouped_pivot = sdf_school_taz_grouped.pivot(index='TAZ', \n",
    "                                                            columns='TYPE', \n",
    "                                                            values='ENROLLMENT').reset_index()\n",
    "# merge to sdf_taz to get all tazs\n",
    "sdf_taz_school = pd.merge(sdf_taz, sdf_school_taz_grouped_pivot, how='left', on='TAZ')\n",
    "\n",
    "# drop SHAPE column\n",
    "sdf_taz_school = sdf_taz_school.drop(columns='SHAPE')\n",
    "# fill NA with 0 for all rows\n",
    "sdf_taz_school = sdf_taz_school.fillna(0)\n",
    "# cast all fields to int\n",
    "sdf_taz_school = sdf_taz_school.astype(int)\n",
    "# rename columns\n",
    "sdf_taz_school.rename(columns={'Elementary School':'elementary_school_enrollment',\n",
    "                               'Middle School':'middle_school_enrollment',\n",
    "                               'High School':'high_school_enrollment',\n",
    "                               'College':'college_enrollment'}, inplace=True)\n",
    "\n",
    "# export to csv\n",
    "sdf_taz_school.to_csv(os.path.join('SchoolEnrollment.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socio Econ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Census data\n",
    "census_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "df_census = get_fs_data(census_url)\n",
    "df_census_2022 = df_census[(df_census['year_sample'] == 2022) & (df_census['sample_level'] == 'block group')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant census variables and calculate rates at block group level\n",
    "# Get Occupancy Data - B25002_003E = Vacant, B25002_002E = Occupied , B25004_006E = Vacant Seasonal\n",
    "occupancy_codes = ['B25002_003E','B25002_002E', 'B25004_006E']\n",
    "df_census_occupancy = df_census_2022[df_census_2022['variable_code'].isin(occupancy_codes)]\n",
    "df_census_occupancy = df_census_occupancy[['TRPAID', 'variable_code', 'value']]\n",
    "# pivot to wide format so we can calculate percentages and totals\n",
    "df_census_occupancy = df_census_occupancy.pivot(index='TRPAID', columns='variable_code', values='value').reset_index()\n",
    "# vacant units + occupied units = total units\n",
    "df_census_occupancy['total_units'] = df_census_occupancy['B25002_003E'] + df_census_occupancy['B25002_002E']\n",
    "# occupancy rate = occupied units / total units\n",
    "df_census_occupancy['occupancy_rate'] = df_census_occupancy['B25002_002E'] / df_census_occupancy['total_units']\n",
    "# seasonal rate = seasonal units / total units\n",
    "df_census_occupancy['seasonal_rate'] = df_census_occupancy['B25004_006E'] / df_census_occupancy['total_units']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Household Size Data - B25010_001E = Total Households\n",
    "df_census_household_size = df_census_2022[df_census_2022['variable_code'] == 'B25010_001E']\n",
    "df_census_household_size = df_census_household_size[['TRPAID', 'variable_code', 'value']]\n",
    "df_census_household_size = df_census_household_size.pivot(index='TRPAID', columns='variable_code', values='value').reset_index()\n",
    "df_census_household_size['household_size'] = df_census_household_size['B25010_001E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Codes by the category they fall into - Census categroy to broader category\n",
    "code_lookup = pd.read_csv('Lookup_Lists/occupancy_census_codes.csv')\n",
    "#Filter census so only variable codes in the code lookup are included\n",
    "df_census_income = df_census_2022[df_census_2022['variable_code'].isin(code_lookup['variable_code'])]\n",
    "#Create a new column that has a value from code lookup based on the variable code\n",
    "df_census_income['income_category'] = df_census_income['variable_code'].map(code_lookup.set_index('variable_code')['category'])\n",
    "#group by block group and income category and sum the values\n",
    "df_census_income = df_census_income.groupby(['TRPAID','income_category'])['value'].sum().reset_index()\n",
    "df_census_income = df_census_income.pivot(index='TRPAID', columns='income_category', values='value').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRPAID is a 16 digit ID, but it is imported as a float. Convert to string and to retain leading zeros\n",
    "df_census_household_size['TRPAID']= df_census_household_size['TRPAID'].astype(str).str.zfill(16)\n",
    "df_census_income['TRPAID']= df_census_income['TRPAID'].astype(str).str.zfill(16)\n",
    "# merge all the census data together\n",
    "df_census_occupancy_all = pd.merge(df_census_occupancy, df_census_household_size, on='TRPAID', how='left')\n",
    "df_census_all = pd.merge(df_census_occupancy_all, df_census_income, on='TRPAID', how='left')\n",
    "# rename columns of df_census_all\n",
    "column_rename = {\n",
    "    'B25002_003E': 'vacant_units',\n",
    "    'B25002_002E': 'occupied_units',\n",
    "    'B25004_006E': 'seasonal_units',\n",
    "    'High Income': 'high_income',\n",
    "    'Low Income': 'low_income',\n",
    "    'Medium Income': 'middle_income',\n",
    "}\n",
    "df_census_all.rename(columns=column_rename, inplace=True)\n",
    "\n",
    "df_census_all.drop(columns=['B25010_001E'], inplace=True)\n",
    "# calculate proportions of income categories\n",
    "df_census_all['high_income_proportion'] = df_census_all['high_income'] / df_census_all['occupied_units']\n",
    "df_census_all['middle_income_proportion'] = df_census_all['middle_income'] / df_census_all['occupied_units']\n",
    "df_census_all['low_income_proportion'] = df_census_all['low_income'] / df_census_all['occupied_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate a block group level number of units and vhrs so we can get to adjusted seasonal rates\n",
    "df_units_block_grouped = sdf_units_block.groupby('TRPAID').agg({'Residential_Units': 'sum'}).reset_index()\n",
    "df_vhr_grouped     = sdf_vhr_block.groupby('TRPAID').agg({'APN': 'count'}).reset_index()\n",
    "# merge the two dataframes\n",
    "df_units_vhr = pd.merge(df_units_block_grouped, df_vhr_grouped, on='TRPAID', how='left')\n",
    "#rename APN to VHR\n",
    "df_units_vhr.rename(columns={'APN':'VHR'}, inplace=True)\n",
    "# fill in missing values with 0\n",
    "df_units_vhr = df_units_vhr.fillna(0)\n",
    "df_units_vhr['non_vhr_units'] = df_units_vhr['Residential_Units'] - df_units_vhr['VHR']\n",
    "# join this to the census data \n",
    "df_census_vhr = pd.merge(df_census_all, df_units_vhr, on='TRPAID', how='left')\n",
    "# calculate the non-adjusted number of seasonal units and then subtract the number of VHRs\n",
    "df_census_vhr['non_adjusted_seasonal_units'] = df_census_vhr['seasonal_rate']*df_census_vhr['Residential_Units']\n",
    "df_census_vhr['adjusted_seasonal_units'] = df_census_vhr['non_adjusted_seasonal_units'] - df_census_vhr['VHR']\n",
    "# Manually adjust the seasonal units for block group 3200500170022020 because of a lag in the data\n",
    "# The census reports 100% occupancy but I think it has to do with the beach club development\n",
    "df_census_vhr.loc[df_census_vhr['TRPAID'] == '3200500170022020', 'adjusted_seasonal_units'] = 0\n",
    "# calculate the adjusted seasonal rate\n",
    "df_census_vhr['adjusted_seasonal_rate'] = df_census_vhr['adjusted_seasonal_units'] / df_census_vhr['Residential_Units']\n",
    "# rename a final database\n",
    "df_census_final = df_census_vhr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a parcel layer with all of the census rates applied by merging df_census_final with sdf_units_block\n",
    "sdf_units_census_values = pd.merge(sdf_units_block, df_census_final, on='TRPAID', how='left')\n",
    "#This can eventually be grouped at the TAZ level or joined to the master parcel dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top line employment data for NV from 2018 lives here: ????\n",
    "# we got employment data from NV at the Tahoe Basin level by NAICS code....\n",
    "\n",
    "# get the employment data\n",
    "nv_employ = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE HAVE GOOD DATA FOR CASINO EMPLOYMENT on the South Shore ## \n",
    "# for employment data we have multiple years of CA EDD data\n",
    "# california employment development department data for 2018 and 2022 was transformed to a feature class and spatial joined to TAZs and Block Group\n",
    "# exported to a csv\n",
    "# stacekd data by temporal scale\n",
    "# grouped by TAZ and NAICS code, and summed employment\n",
    "# F:\\GIS\\PROJECTS\\ResearchAnalysis\\Employment\\Data\\EDD_Grouped\n",
    "# F:\\GIS\\PROJECTS\\ResearchAnalysis\\Employment\\\n",
    "# then looking at difference of total and trends over time (month-month) and year over year\n",
    "#\n",
    "# LODES data https://maps.trpa.org/server/rest/services/LTinfo_Climate_Resilience_Dashboard/MapServer/142\n",
    "\n",
    "# compare 2018 to 2022 by block group \n",
    "\n",
    "# checking trends of each. \n",
    "#  - what is the trend of employment by NAICS code\n",
    "#  - what is the trend of employment by TAZ\n",
    "#  - what is the trend of employment by block group\n",
    "#  - what is the trend of employment by zip code\n",
    "# \n",
    "# CBP data for 2018 and 2022\n",
    "# data is mostly in the service. or in Vector.sde>Census>Jobs\n",
    "# look at comparisons of trends by same geography and temporal scale\n",
    "\n",
    "# workflow is to get the data, clean it, join it to the spatial data, then group by the spatial data and sum the employment\n",
    "# \n",
    "# establish trends for CA for the three datasources...compare the trends and see if they are similar\n",
    "# \n",
    "\n",
    "### NAICS codes are one order higher in LODES data, CA EDD and CBP data have the same granularity of NAICS codes\n",
    "### LODES is by year so the trend might be different if there is a sesaonal component to the data\n",
    "\n",
    "# we'll have two of the three datasets analyzed for Nevada and all three in California.\n",
    "    # where we have all three datasets we'll compare the trends and see if they are similar\n",
    "    # we'll look at the trends for each dataset and see if they are similar\n",
    "    # we'll look at the trends for each geography and see if they are similar\n",
    "    # we'll look at the trends for each temporal scale and see if they are similar\n",
    "\n",
    "# For Nevada we have block level data for 2018 so if consistent with 2022 we can use that as a proxy for 2022\n",
    "\n",
    "# we subtract out any known employment from the 2018 data (e.g. Lakeside Inn) and compare the trends\n",
    "# generate adjustment factors by sector and apply those adjustments to the 2018 data that was aggregated to the TAZ level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAZ Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scaling Factor Data Engineering\n",
    "\n",
    "> Needs\n",
    "\n",
    "* Place.ai data by Jurisdiction ?\n",
    "\n",
    "* Model day(s) weighting logic\n",
    "    * will we need July data? \n",
    "\n",
    "* for quarterly data by zone\n",
    "    * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basin Summary Category\n",
    "* lodging occupancy rate\n",
    "* campground occupancy rate\n",
    "* house(VHR) rate\n",
    "* seasonal rate\n",
    "* lodging unit\n",
    "* campground\n",
    "* percentHouseSeasonal\n",
    "* school enrollment\n",
    "* employment\n",
    "* residential unit\n",
    "* total persons\n",
    "* census occupancy rate\n",
    "* low income res unit\n",
    "* medium income res unit\n",
    "* high income res unit\n",
    "* total occupied unit\n",
    "* persons per occupied unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
