{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel Demand Model Data Inputs\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working directory and git repository path\n",
    "local_path = pathlib.Path().absolute()\n",
    "repo_path = pathlib.Path(local_path).parents[1]\n",
    "# set workspace\n",
    "arcpy.env.workspace = os.path.join(local_path, 'Workspace.gdb')\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current working directory:', local_path)\n",
    "print('Repository directory:', repo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "* old inputs: F:\\Research and Analysis\\misc\\Reid_Haefer\\Model\\model_update_2018\\data_inputs\\lodging_occupancy\n",
    "* Final inputs to produce: F:\\Transportation\\model\\scenario_base\\zonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get TAZ geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)\n",

    "#set spatial reference\n",
    "sdf_taz.spatial.sr = 4326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get block group geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_groups_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/27'\n",
    "sdf_block_groups = get_fs_data_spatial(block_groups_url)\n",
    "sdf_block_groups = sdf_block_groups[(sdf_block_groups['YEAR'] == 2020) & (sdf_block_groups['GEOGRAPHY'] == 'Block Group')]\n",
    "sdf_block_groups.spatial.sr = 4326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Existing Development Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_units = get_fs_data_spatial_query(units_url, \"Year = 2022\")\n",
    "sdf_units.spatial.sr = 4326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get VHR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vhr_url = 'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\n",
    "sdf_vhr = get_fs_data_spatial(vhr_url)\n",
    "sdf_vhr.spatial.sr = 4326\n",
    "sdf_vhr = sdf_vhr[(sdf_vhr['Status'] == 'Active')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_taz_crosswalk(parcel_fc, taz_fc, geography_fc):\n",
    "        # Define in-memory feature class names\n",
    "    geo_feature_class = r\"in_memory\\geo\"\n",
    "    taz_feature_class = r\"in_memory\\taz_geo\"\n",
    "\n",
    "    # Perform first spatial join - order doesn't matter\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=parcel_fc,\n",
    "        join_features=taz_fc,\n",
    "        out_feature_class=taz_feature_class,\n",
    "        join_operation=\"JOIN_ONE_TO_MANY\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        match_option=\"HAVE_THEIR_CENTER_IN\"\n",
    "    )\n",
    "\n",
    "    # Perform second spatial join\n",
    "    arcpy.analysis.SpatialJoin(\n",
    "        target_features=taz_feature_class,\n",
    "        join_features=geography_fc,\n",
    "        out_feature_class=geo_feature_class,\n",
    "        join_operation=\"JOIN_ONE_TO_MANY\",\n",
    "        join_type=\"KEEP_ALL\",\n",
    "        match_option=\"HAVE_THEIR_CENTER_IN\"\n",
    "    )\n",
    "\n",
    "    # Convert the final joined feature class to a Spatially enabled DataFrame\n",
    "    sdf_taz_geo = pd.DataFrame.spatial.from_featureclass(geo_feature_class)\n",
    "\n",
    "    # Select and rename necessary columns\n",
    "    sdf_taz_geo = sdf_taz_geo[['APN', 'GEOID', 'TRPAID', 'TAZ_1', 'Residential_Units',\n",
    "                            'TouristAccommodation_Units', 'CommercialFloorArea_SqFt']]\n",
    "    sdf_taz_geo = sdf_taz_geo.rename(columns={'TAZ_1': 'TAZ'})\n",
    "\n",
    "    # Group by and aggregate data\n",
    "    df_parcels_grouped = sdf_taz_geo.groupby(['TAZ', 'TRPAID']).agg({'Residential_Units': 'sum',\n",
    "                                                                    'TouristAccommodation_Units': 'sum',\n",
    "                                                                    'CommercialFloorArea_SqFt': 'sum'}).reset_index()\n",
    "\n",
    "    # Calculate totals and proportions\n",
    "    df_parcels_grouped['Total_Res_Units'] = df_parcels_grouped.groupby('TAZ')['Residential_Units'].transform('sum')\n",
    "    df_parcels_grouped['Total_TA_Units'] = df_parcels_grouped.groupby('TAZ')['TouristAccommodation_Units'].transform('sum')\n",
    "    df_parcels_grouped['Total_CommercialFloorArea_SqFt'] = df_parcels_grouped.groupby('TAZ')['CommercialFloorArea_SqFt'].transform('sum')\n",
    "    \n",
    "    # Calculate proportions with checks for zero totals\n",
    "    df_parcels_grouped['Residential_Units_Proportion'] = df_parcels_grouped.apply(\n",
    "        lambda row: row['Residential_Units'] / row['Total_Res_Units'] if row['Total_Res_Units'] != 0 else 0, axis=1\n",
    "    )\n",
    "    df_parcels_grouped['TouristAccommodation_Units_Proportion'] = df_parcels_grouped.apply(\n",
    "        lambda row: row['TouristAccommodation_Units'] / row['Total_TA_Units'] if row['Total_TA_Units'] != 0 else 0, axis=1\n",
    "    )\n",
    "    df_parcels_grouped['CommercialFloorArea_SqFt_Proportion'] = df_parcels_grouped.apply(\n",
    "        lambda row: row['CommercialFloorArea_SqFt'] / row['Total_CommercialFloorArea_SqFt'] if row['Total_CommercialFloorArea_SqFt'] != 0 else 0, axis=1\n",
    "    )\n",
    "\n",
    " \n",
    "    # Fill NaN values with 0\n",
    "    df_parcels_grouped.fillna(0, inplace=True)\n",
    "    return df_parcels_grouped\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_block_group_crosswalk = make_taz_crosswalk(sdf_units, sdf_taz, sdf_block_groups)\n",
    "taz_block_group_crosswalk.to_csv('taz_block_group_crosswalk.csv', index=False)"


    "#QAQC on vhrs and parcels\n",
    "df_vhr_comparison = pd.merge(sdf_vhr, sdf_units, left_on='APN', right_on='APN', how='left')\n",
    "missing_units = df_vhr_comparison[df_vhr_comparison['Residential_Units']==0]\n",
    "missing_units.to_csv('missing_units.csv', index=False)\n"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [

    "# Assign VHRs to TAZs and then group by TAZ\n",
    "\n",
    "vhr_fc = sdf_vhr\n",
    "taz_fc = sdf_taz\n",
    "vhr_taz_feature_class = r\"in_memory\\vhr_geo\"\n",
    "\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features=vhr_fc,\n",
    "    join_features=taz_fc,\n",
    "    out_feature_class=vhr_taz_feature_class,\n",
    "    join_operation=\"JOIN_ONE_TO_MANY\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"HAVE_THEIR_CENTER_IN\"\n",
    ")\n",
    "sdf_vhr_geo = pd.DataFrame.spatial.from_featureclass(vhr_taz_feature_class)"

   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [

    "taz_vhr_grouped = sdf_vhr_geo.groupby('TAZ').agg({'APN': 'count'}).reset_index()\n",
    "taz_vhr_grouped = taz_vhr_grouped.rename(columns={'APN': 'VHR_Count'})"

   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socio Econ\n",
    "> TAZ by total_residential_units,census_occ_rate,total_occ_units,occ_units_low_inc,occ_units_med_inc,occ_units_high_inc,persons_per_occ_unit,total_persons,emp_retail,emp_srvc,emp_rec,emp_game,emp_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [

    "census_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "df_census = get_fs_data(census_url)\n",
    "df_census_2022 = df_census[(df_census['year_sample'] == 2022) & (df_census['sample_level'] == 'block group')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_codes = ['B25002_003E','B25002_002E', 'B25004_006E']\n",
    "df_census_occupancy = df_census_2022[df_census_2022['variable_code'].isin(occupancy_codes)]\n",
    "df_census_occupancy = df_census_occupancy[['TRPAID', 'variable_code', 'value']]\n",
    "df_census_occupancy = df_census_occupancy.pivot(index='TRPAID', columns='variable_code', values='value').reset_index()\n",
    "df_census_occupancy['total_units'] = df_census_occupancy['B25002_003E'] + df_census_occupancy['B25002_002E']\n",
    "df_census_occupancy['occupancy_rate'] = df_census_occupancy['B25002_002E'] / df_census_occupancy['total_units']\n",
    "df_census_occupancy['seasonal_rate'] = df_census_occupancy['B25004_006E'] / df_census_occupancy['total_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_household_size = df_census_2022[df_census_2022['variable_code'] == 'B25010_001E']\n",
    "df_census_household_size = df_census_household_size[['TRPAID', 'variable_code', 'value']]\n",
    "df_census_household_size = df_census_household_size.pivot(index='TRPAID', columns='variable_code', values='value').reset_index()\n",
    "df_census_household_size['household_size'] = df_census_household_size['B25010_001E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorize the income variables from the census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_lookup = pd.read_csv('Lookup_Lists/occupancy_census_codes.csv')\n",
    "#Filter census so only variable codes in the code lookup are included\n",
    "df_census_income = df_census_2022[df_census_2022['variable_code'].isin(code_lookup['variable_code'])]\n",
    "#Create a new column that has a value from code lookup based on the variable code\n",
    "df_census_income['income_category'] = df_census_income['variable_code'].map(code_lookup.set_index('variable_code')['category'])\n",
    "#group by block group and income category and sum the values\n",
    "df_census_income = df_census_income.groupby(['TRPAID','income_category'])['value'].sum().reset_index()\n",
    "df_census_income = df_census_income.pivot(index='TRPAID', columns='income_category', values='value').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_household_size['TRPAID']= df_census_household_size['TRPAID'].astype(str).str.zfill(16)\n",
    "df_census_income['TRPAID']= df_census_income['TRPAID'].astype(str).str.zfill(16)\n",
    "df_census_occupancy_all = pd.merge(df_census_occupancy, df_census_household_size, on='TRPAID', how='left')\n",
    "df_census_all = pd.merge(df_census_occupancy_all, df_census_income, on='TRPAID', how='left')\n",
    "# rename columns of df_census_all\n",
    "column_rename = {\n",
    "    'B25002_003E': 'vacant_units',\n",
    "    'B25002_002E': 'occupied_units',\n",
    "    'B25004_006E': 'seasonal_units',\n",
    "    'High Income': 'high_income',\n",
    "    'Low Income': 'low_income',\n",
    "    'Medium Income': 'middle_income',\n",
    "}\n",
    "df_census_all.rename(columns=column_rename, inplace=True)\n",
    "df_census_all.drop(columns=['B25010_001E'], inplace=True)\n",
    "df_census_all['high_income_proportion'] = df_census_all['high_income'] / df_census_all['occupied_units']\n",
    "df_census_all['middle_income_proportion'] = df_census_all['middle_income'] / df_census_all['occupied_units']\n",
    "df_census_all['low_income_proportion'] = df_census_all['low_income'] / df_census_all['occupied_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the proportions in sdf_taz_bg to assign proportion of block group values to taz\n",
    "taz_values_acs = taz_block_group_crosswalk.merge(df_census_all, left_on='TRPAID', right_on='TRPAID', how='left')\n",
    "taz_values_acs = taz_values_acs.merge(taz_vhr_grouped, on='TAZ', how='left')\n",
    "taz_values_acs.fillna(0, inplace=True)\n",
    "# Calculate the number of seasonal units we think are in each TAZ\n",
    "#Remove VHRs from seasonal units so that we can get just vacation/second homes\n",
    "#taz_values_acs['adjusted_seasonal_units'] = taz_values_acs['seasonal_units']-taz_values_acs['VHR_Count']\n",
    "#taz_values_acs['seasonal_rate'] = taz_values_acs['adjusted_seasonal_units'] / taz_values_acs['total_units']\n",
    "#Create proportional values based on how many proportion of residential units are in each TAZ\n",
    "taz_values_acs['adjusted_occupancy'] = taz_values_acs['occupancy_rate'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_high_income'] = taz_values_acs['high_income_proportion'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_middle_income'] = taz_values_acs['middle_income_proportion'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_low_income'] = taz_values_acs['low_income_proportion'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_seasonal_rate'] = taz_values_acs['seasonal_rate'] * taz_values_acs['Residential_Units_Proportion']\n",
    "#Group by TAZ and sum the values\n",
    "taz_values_grouped_occupancy = taz_values_acs.groupby('TAZ').agg({'adjusted_occupancy': 'sum',\n",
    "                                                                  'adjusted_seasonal_rate': 'sum',\n",
    "                                                                  'adjusted_high_income':'sum',\n",
    "                                                                  'adjusted_middle_income': 'sum',\n",
    "                                                                  'adjusted_low_income': 'sum'}).reset_index()\n",
    "#This is just the input values for the TAZs\n",
    "taz_values_grouped_occupancy.to_csv('taz_calibration_values.csv', index=False)\n",
    "#This provides the raw data for troubleshooting\n",
    "taz_values_acs.to_csv('taz_values_acs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the proportions by the total number of units in the TAZ\n",
    "taz_residential_units = taz_block_group_crosswalk.groupby('TAZ')['Residential_Units'].sum().reset_index()\n",
    "taz_residential_units = taz_residential_units.merge(taz_values_grouped_occupancy, on='TAZ', how='left')\n",
    "taz_residential_units = taz_residential_units.merge(taz_vhr_grouped, on='TAZ', how='left')\n",
    "taz_residential_units['occupancy'] = taz_residential_units['adjusted_occupancy'] * taz_residential_units['Residential_Units']\n",
    "taz_residential_units['total_seasonal_units'] = taz_residential_units['adjusted_seasonal_rate'] * taz_residential_units['Residential_Units']\n",
    "taz_residential_units['adjusted_season_units'] = taz_residential_units['total_seasonal_units'] - taz_residential_units['VHR_Count']\n",
    "# Adjust income proportions by the total number of residential units and adjusted occupancy in each TAZ\n",
    "taz_residential_units['high_income'] = (taz_residential_units['adjusted_high_income'] * \n",
    "                                                    taz_residential_units['Residential_Units'] * \n",
    "                                                    taz_residential_units['adjusted_occupancy'])\n",
    "\n",
    "taz_residential_units['middle_income'] = (taz_residential_units['adjusted_middle_income'] * \n",
    "                                                    taz_residential_units['Residential_Units'] * \n",
    "                                                    taz_residential_units['adjusted_occupancy'])\n",
    "\n",
    "taz_residential_units['low_income'] = (taz_residential_units['adjusted_low_income'] * \n",
    "                                                taz_residential_units['Residential_Units'] * \n",
    "                                                taz_residential_units['adjusted_occupancy'])\n",
    "taz_residential_units.to_csv('taz_calibration_values_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a feature layer for the TDM variables. Not sure we need or want this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tahoe_geography_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/27'\n",
    "# Create a FeatureLayer object directly from the REST map service URL\n",
    "feature_layer = FeatureLayer(tahoe_geography_url)\n",
    "\n",
    "# Create a spatial DataFrame from the FeatureLayer\n",
    "sdf = GeoAccessor.from_layer(feature_layer)\n",
    "\n",
    "merged_df = pd.merge(sdf, df_census_all, on='TRPAID', how='inner')\n",
    "columns_drop=['GlobalID', 'YEAR', 'created_date',  'created_user', 'last_edited_date', 'last_edited_user', 'Shape.STArea()', 'Shape.STLength()']\n",
    "merged_df = merged_df.drop(columns=columns_drop)\n",
    "workspace = r\"F:\\GIS\\PROJECTS\\ResearchAnalysis\\Demographics\\Workspace.gdb\"\n",
    "## Export spatial dataframes to feature class to use in Spatial join\n",
    "merged_df.spatial.to_featureclass(os.path.join(workspace, \"Tahoe_BlockGroup_TDM_Values\"), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: Assign employees to TAZs\n",
    "* Data Axle data and CBP data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_url = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income by Residential Unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: Calculate #/% of residential units in low/mid/high income in each TAZ\n",
    "* Get # of HH in each income bin by census block group from ACS\n",
    "* Combine to low/mid/high income, with breaks at 60k and 100k\n",
    "* Assign to TAZ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# place holder URL - Demographics URL will have a new Feature Service titled \"Block Group 2022 - Travel Demand Model Inputs\"\n",
    "census_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/1'\n",
    "sdf_census = get_fs_data_spatial(census_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overnight Visitation\n",
    ">TAZ by hotelmotel,resort,casino,campground,percentHouseSeasonal,beach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv that matches:\n",
    "df_visit = pd.read_csv(os.path.join(repo_path,r\"TravelDemandModel\\2022\\data\\model_inputs\\OvernightVisitorZonalData_Summer.csv\"))\n",
    "df_visit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tourist Accommodation Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get VHR data - this is current, no way to get historical data outside of the City of South Lake Tahoe\n",
    "# vhr_url = 'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\n",
    "# sdf_vhr = get_fs_data_spatial(vhr_url)\n",
    "\n",
    "# Get Tourist Accomodation Units data\n",
    "tau_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_tau = get_fs_data_spatial_query(tau_url, \"Year = 2022\")\n",
    "\n",
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set TAU_Type to null text field\n",
    "sdf_tau['TAU_Type'] = None\n",
    "# columns to keep\n",
    "tau_columns = ['APN',\n",
    "                'TouristAccommodation_Units', 'YEAR',\n",
    "                'JURISDICTION', 'COUNTY', 'OWNERSHIP_TYPE',\n",
    "                'EXISTING_LANDUSE', 'TAZ', 'TAU_Type',\n",
    "                'WITHIN_TRPA_BNDY', 'PARCEL_ACRES', 'PARCEL_SQFT', 'SHAPE']\n",
    "# filter to columns\n",
    "sdf_tau = sdf_tau[tau_columns]\n",
    "\n",
    "# get only parcels with tourist accomodation units\n",
    "sdf_tau = sdf_tau[sdf_tau['TouristAccommodation_Units'] > 0]\n",
    "sdf_tau.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# casino or resort parcels\n",
    "casino_apns = [# south shore\n",
    "                '1318-27-002-002','1318-27-002-005','1318-27-001-009','1318-27-001-021'\n",
    "               # north shore\n",
    "               '123-031-01', '123-042-01', '123-052-04', '123-042-15']\n",
    "\n",
    "resort_apns = [# LT resort, hyatt, hilton, >?\n",
    "                '127-280-02','029-480-004','027-090-025']\n",
    "\n",
    "# set TAU_Type feild values to Hotel/Motel, Casino, or Resort\n",
    "sdf_tau['TAU_Type'] = \"Hotel/Motel\"\n",
    "# if the APN is in the list of casino APNs, set the TAU Type to Casino\n",
    "sdf_tau.loc[sdf_tau['APN'].isin(casino_apns), 'TAU_Type'] = \"Casino\"\n",
    "# if the APN is in the list of resort APNs, set the TAU Type to Resort\n",
    "sdf_tau.loc[sdf_tau['APN'].isin(resort_apns), 'TAU_Type'] = \"Resort\"\n",
    "\n",
    "sdf_tau.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spatial join TAZ data to TAU data\n",
    "arcpy.SpatialJoin_analysis(sdf_tau, sdf_taz, 'taz_tau', \n",
    "                           'JOIN_ONE_TO_ONE', 'KEEP_ALL', \n",
    "                           match_option='HAVE_THEIR_CENTER_IN')\n",
    "# read in output of spatial join as sdf\n",
    "sdf_tau_taz = pd.DataFrame.spatial.from_featureclass('taz_tau')\n",
    "# set TAZ = to TAZ_1\n",
    "sdf_tau_taz['TAZ'] = sdf_tau_taz['TAZ_1']\n",
    "# keep columns\n",
    "sdf_tau_taz = sdf_tau_taz[tau_columns]\n",
    "\n",
    "# group by TAU_Type and sum of TouristAccommodation_Units within TAZ\n",
    "sdf_tau_taz_grouped = sdf_tau_taz.groupby(['TAU_Type', 'TAZ']).agg(\n",
    "                                                {'TouristAccommodation_Units': 'sum'}).reset_index()\n",
    "# unstack by TAU_Type as columns and TAZ as a column\n",
    "sdf_tau_taz_grouped_pivot = sdf_tau_taz_grouped.pivot(index='TAZ', \n",
    "                                                      columns='TAU_Type', \n",
    "                                                      values='TouristAccommodation_Units').reset_index()\n",
    "# merge to sdf_taz to get all tazs\n",
    "sdf_taz_tau = pd.merge(sdf_taz, sdf_tau_taz_grouped_pivot, how='left', on='TAZ')\n",
    "\n",
    "# rename columns\n",
    "sdf_taz_tau.rename(columns={'Hotel/Motel':'hotelmotel',\n",
    "                            'Casino':'casino',\n",
    "                            'Resort':'resort'}, inplace=True)\n",
    "\n",
    "# set columns\n",
    "sdf_taz_tau['campground'] = 0\n",
    "sdf_taz_tau['percentHouseSeasonal'] = 0\n",
    "\n",
    "# keep only columns of interest\n",
    "sdf_taz_tau = sdf_taz_tau[['TAZ', 'hotelmotel', 'casino', 'resort','campground','percentHouseSeasonal']]\n",
    "sdf_taz_tau = sdf_taz_tau.fillna(0)\n",
    "# cast all fields to int\n",
    "sdf_taz_tau = sdf_taz_tau.astype(int)\n",
    "\n",
    "# export to csv\n",
    "sdf_taz_tau.to_csv(os.path.join('OvernightVisitorZonalData_Summer.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total TAUs by TAU_Type\n",
    "sdf_tau_type = sdf_tau.groupby('TAU_Type').agg({'TouristAccommodation_Units':'sum'}).reset_index()\n",
    "# add total row\n",
    "sdf_tau_type.loc['Total'] = sdf_tau_type.sum(numeric_only=True)\n",
    "\n",
    "sdf_tau_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: calculate campground occupancy on model day and assign to TAZs\n",
    "* in-process data: \"F:\\Research and Analysis\\Transportation\\Travel_Demand_Model\\2023 Update\\Input Data\\Campgrounds\\Campground_Visitation.xlsx\"\n",
    "* USFS data: https://apps.fs.usda.gov/arcx/rest/services/EDW/EDW_RecreationAreaActivities_01/MapServer/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "campgroundu_url = 'https://maps.trpa.org/server/rest/services/Recreation/MapServer/1'\n",
    "# campgrounds\n",
    "sdf_campgrounds = get_fs_data_spatial_query(campgroundu_url, \"RECREATION_TYPE = 'Campground\")\n",
    "\n",
    "# campground visitation\n",
    "df_campground_visitation = pd.read_csv('2022/Data/Campground_Visitation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CA SP info https://csparks.maps.arcgis.com/apps/webappviewer/index.html?id=f96a883ff4154455b23bdc119f4574a9\n",
    "# CA SP visitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "# get data params with Mason's API key\n",
    "campsite_url = 'https://ridb.recreation.gov/api/v1/facilities/232768/campsites'\n",
    "api = '45310cc1-df4f-4824-88ba-8bd75d06f57e'\n",
    "params = {'apikey': api}\n",
    "\n",
    "# rec data from https://ridb.recreation.gov/download\n",
    "# https://ridb.recreation.gov/downloads/reservations2022.zip\n",
    "# local copy\n",
    "rec_gov = r\"C:\\Users\\mbindl\\Downloads\\reservations2022\\FY22 Historical Reservations Full.csv\"\n",
    "df_res = pd.read_csv(rec_gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty data frame to store campsite info\n",
    "df_campsite_info_all = pd.DataFrame(columns=['Campground','Campsites', 'Total Nights', 'Total Visitors'])\n",
    "\n",
    "# get campsite info from recreation.gov api\n",
    "campgound_ids = {'232768':'Nevada Beach Campground',\n",
    "                 '232769':'Fallen Leaf Campground',\n",
    "                 '232876':'Meeks Bay Campground',\n",
    "                 '232874':'William Kent Campground',\n",
    "                 '232875':'Kaspian Campground',}\n",
    "\n",
    "# create loop of campgrounds ids and get requests and count campsites\n",
    "for campsite_id, campsite_name in campgound_ids.items():\n",
    "    campsite_url = f'https://ridb.recreation.gov/api/v1/facilities/{campsite_id}/campsites'\n",
    "    # get data for \"Nevada Beach Campground\"\n",
    "    campsite_data = requests.get(campsite_url, params=params).json()\n",
    "    # parse the data into a dataframe\n",
    "    df_campsite = pd.DataFrame(campsite_data['RECDATA'])\n",
    "    # count campsites\n",
    "    print(f'{campsite_name} has {df_campsite.CampsiteName.count()} campsites')\n",
    "    site_count = df_campsite.CampsiteName.count()\n",
    "\n",
    "    # filter by campground id from the downloaded data\n",
    "    df = df_res[df_res.facilityid == int(campsite_id)]\n",
    "    # filter to usetype = Overnight\n",
    "    df = df[df.usetype == 'Overnight']\n",
    "    # filter by August 2022\n",
    "    df_august22 = df[df.startdate.str.contains('2022-08')]\n",
    "    # # filter out cancelled reservations\n",
    "    # df_august22 = df_august22[df_august22.status != 'Cancelled']\n",
    "    # # filter out reservations with 0 nights\n",
    "    # df_august22 = df_august22[df_august22.nights != '0']\n",
    "    # filter out reservations with end date in September 2022\n",
    "    df_august22 = df_august22[~df_august22.enddate.str.contains('2022-09')]\n",
    "    # use .loc to strip off ' days' from the nights column\n",
    "    df_august22.loc[:, 'nights'] = df_august22.nights.map(lambda x: x.rstrip(' days'))\n",
    "    # use .loc to strip off ' day' from the nights column\n",
    "    df_august22.loc[:, 'nights'] = df_august22.nights.map(lambda x: x.rstrip(' day'))\n",
    "    # drop a specific row based on a value in nights column\n",
    "    df_august22 = df_august22[df_august22.nights != '00:00:00']\n",
    "    # convert nights column to integer\n",
    "    df_august22.nights = df_august22.nights.astype(int)\n",
    "\n",
    "    # number of nights reserved for Nevada Beach Campground in August 2022\n",
    "    total_nights = df_august22.nights.sum()\n",
    "    # get total number of people reserved for Nevada Beach Campground in August 2022\n",
    "    total_people = df_august22.numberofpeople.sum()\n",
    "    print(f'{campsite_name} had {total_nights} nights reserved and {total_people} total visitors during August 2022')\n",
    "    # append as row to new dataframe with campsite name, total nights, and total people\n",
    "    df_campsite_info = pd.DataFrame([[campsite_name, site_count, total_nights, total_people]], \n",
    "                                    columns=['Campground', 'Campsites','Total Nights', 'Total Visitors'])\n",
    "    \n",
    "    # Check if 'df_campsite_info_all' exists in the local namespace\n",
    "    if 'df_campsite_info_all' in locals():\n",
    "        # If it exists, append 'df_campsite_info' to it as a new row\n",
    "        df_campsite_info_all = pd.concat([df_campsite_info_all, df_campsite_info], ignore_index=True)\n",
    "    else:\n",
    "        # If it doesn't exist, assign 'df_campsite_info' to it directly\n",
    "        df_campsite_info_all = df_campsite_info.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create loop of campgrounds ids and get requests and count campsites\n",
    "for campsite_id, campsite_name in campgound_ids.items():\n",
    "    campsite_url = f'https://ridb.recreation.gov/api/v1/facilities/{campsite_id}/campsites'\n",
    "    # get data for \"Nevada Beach Campground\"\n",
    "    campsite_data = requests.get(campsite_url, params=params).json()\n",
    "    # parse the data into a dataframe\n",
    "    df_campsite = pd.DataFrame(campsite_data['RECDATA'])\n",
    "    # count campsites\n",
    "    print(f'{campsite_name} has {df_campsite.CampsiteName.count()} campsites')\n",
    "    site_count = df_campsite.CampsiteName.count()\n",
    "\n",
    "    # filter by campground id from the downloaded data\n",
    "    df = df_res[df_res.facilityid == int(campsite_id)]\n",
    "    # filter to usetype = Overnight\n",
    "    df = df[df.usetype == 'Overnight']\n",
    "    # filter by August 2022\n",
    "    df_august22 = df[df.startdate.str.contains('2022-08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_august22.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campsite_info_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any reservation that has an enddate in september\n",
    "df_res_august = df_res[~df_res.enddate.str.contains('2022-09')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupancy Rates\n",
    "> TAZ by hotelmotel,resort,casino,campground,house,seasonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lodging Occupancy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: calculate occupancy rates for hotels and VHRs and assign to TAZs\n",
    "\n",
    "* Placer has Occupancy data at the TOT tax district. Josh will get the spatial file from Placer County GIS. \n",
    "* City of South Lake has hotel level occupancy data that needs to be converted to a spatial file. Reports live here: https://www.cityofslt.us/805/Zone-Detail-Reports \n",
    "* Douglas County has occupancy rates from the Casino reports: https://gaming.nv.gov/about/abstract/report/\n",
    "* Washoe County has occupancy rates at the District level from RSCVA (single number by type of occupancy) \"F:\\Research and Analysis\\Visitation\\occupancy\\Washoe B Occupied Rooms by Market Segment - 2022.xlsx\"\n",
    "* Rest of El Dorado County? is only VHRs, estimating Occupancy Rates based on TOT rates F:\\Research and Analysis\\Visitation\\occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get VHR data - this is current, no way to get historical data outside of the City of South Lake Tahoe\n",
    "vhr_url = 'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\n",
    "sdf_vhr = get_fs_data_spatial(vhr_url)\n",
    "\n",
    "# Get Tourist Accomodation Units data\n",
    "tau_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_tau = get_fs_data_spatial_query(tau_url, \"Year = 2022\")\n",
    "\n",
    "# get occupancy rate data - see above for sources\n",
    "df_occupancy = pd.read_csv('TravelDemandModel\\2022\\data\\Occupancy_Rate.csv')\n",
    "\n",
    "# get occupance rate zone data\n",
    "sdf_occupancy_zones = get_fs_data_spatial('https://maps.trpa.org/server/rest/services/Travel_Demand_Model/MapServer/1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing Occupancy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: estimate household size in each occupied housing unit\n",
    "* get total Residential Units aggregated to TAZ\n",
    "* get total VHRs aggregated to TAZ\n",
    "* apply occupancy rate from ACS\n",
    "* ACS 2022 by Block Group - household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Houshold Block Group data\n",
    "\n",
    "df_census_household_size = df_census_2022[df_census_2022['variable_code'] == 'B25010_001E']\n",
    "df_census_household_size = df_census_household_size[['TRPAID', 'variable_code', 'value']]\n",
    "df_census_household_size_taz = taz_block_group_crosswalk.merge(df_census_household_size, on='TRPAID', how='left')\n",
    "df_census_household_size_taz['household_size_proportion'] = df_census_household_size_taz['value']*df_census_household_size_taz['Residential_Units_Proportion']\n",
    "taz_household_size = df_census_household_size_taz.groupby('TAZ')['household_size_proportion'].sum().reset_index()\n",
    "taz_household_size.to_csv('taz_household_size.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Enrollment\n",
    "> TAZ by elementary_school_enrollment,middle_school_enrollment,high_school_enrollment,college_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: Collate school enrollment files\n",
    "* create spatial file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get School Enrollment data\n",
    "school_url_table     = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/32'\n",
    "df_school_enrollment = get_fs_data(school_url_table)\n",
    "\n",
    "# Get School Enrollment data - spatial\n",
    "school_url_spatial = 'https://maps.trpa.org/server/rest/services/Datadownloader_PlanningandJurisdictions/MapServer/14'\n",
    "sdf_school         = get_fs_data_spatial(school_url_spatial)\n",
    "\n",
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Type to Null\n",
    "sdf_school['TYPE'] = None\n",
    "# set SchoolType to 'elementary' if it contains 'elementary' or 'magnet' or 'academy'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('elementary', case=False), 'TYPE'] = 'Elementary School'\n",
    "# set SchoolType to 'middle' if it contains 'middle'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('middle', case=False), 'TYPE'] = 'Middle School'\n",
    "# set SchoolType to 'high' if it contains 'high'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('high', case=False), 'TYPE'] = 'High School'\n",
    "# set SchoolType to 'college' if it contains 'college'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('college', case=False), 'TYPE'] = 'College'\n",
    "# set SchoolType to 'other' if it it does not contain any of the above\n",
    "sdf_school.loc[sdf_school['TYPE'].isnull(), 'TYPE'] = 'Elementary School'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join TAZs to School points\n",
    "sdf_school_taz = sdf_school.spatial.join(sdf_taz, how='inner')\n",
    "# group by TYPE and sum of Enrollment within TAZ \n",
    "sdf_school_taz_grouped = sdf_school_taz.groupby(['TYPE', 'TAZ']).agg(\n",
    "                                                {'ENROLLMENT': 'sum'}).reset_index()\n",
    "# unstack by TYPE as columns and TAZ as a column\n",
    "sdf_school_taz_grouped_pivot = sdf_school_taz_grouped.pivot(index='TAZ', \n",
    "                                                            columns='TYPE', \n",
    "                                                            values='ENROLLMENT').reset_index()\n",
    "# merge to sdf_taz to get all tazs\n",
    "sdf_taz_school = pd.merge(sdf_taz, sdf_school_taz_grouped_pivot, how='left', on='TAZ')\n",
    "# drop SHAPE column\n",
    "sdf_taz_school = sdf_taz_school.drop(columns='SHAPE')\n",
    "# fill NA with 0 for all rows\n",
    "sdf_taz_school = sdf_taz_school.fillna(0)\n",
    "# cast all fields to int\n",
    "sdf_taz_school = sdf_taz_school.astype(int)\n",
    "# rename columns\n",
    "sdf_taz_school.rename(columns={'Elementary School':'elementary_school_enrollment',\n",
    "                               'Middle School':'middle_school_enrollment',\n",
    "                               'High School':'high_school_enrollment',\n",
    "                               'College':'college_enrollment'}, inplace=True)\n",
    "\n",
    "# export to csv\n",
    "sdf_taz_school.to_csv(os.path.join('SchoolEnrollment.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_taz_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other way using arcpy spatial join and field mappings 'sum' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school_enrollment_22 = df_school_enrollment[df_school_enrollment['Year'] == '2022-2023']\n",
    "# Add a row for LTCC - Lake Tahoe Community College\n",
    "ltcc = {'School_Name': 'Lake Tahoe Community College', 'Level_': 'College', 'Enrollment': 2909}\n",
    "df_school_enrollment_22 = pd.concat([df_school_enrollment_22, pd.DataFrame([ltcc])], ignore_index=True)\n",
    "# join school spatial to school table\n",
    "sdf_school_enroll = pd.merge(sdf_school, df_school_enrollment, left_on='SchoolID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)\n",
    "\n",
    "# Get School Enrollment data - spatial\n",
    "school_url_spatial = 'https://maps.trpa.org/server/rest/services/Datadownloader_PlanningandJurisdictions/MapServer/14'\n",
    "sdf_school         = get_fs_data_spatial(school_url_spatial)\n",
    "\n",
    "\n",
    "# keep only the columns we need; SHAPE and TAZ for TAZ and SHAPE and ENROLLMENT for schools\n",
    "sdf_taz = sdf_taz[['TAZ', 'SHAPE']]\n",
    "sdf_school = sdf_school[['ENROLLMENT', 'SHAPE']]\n",
    "\n",
    "# convert to feature class\n",
    "sdf_taz.spatial.to_featureclass(location=os.path.join(arcpy.env.workspace, 'TAZ'), overwrite=True, sanitize_columns=False)\n",
    "sdf_school.spatial.to_featureclass(location=os.path.join(arcpy.env.workspace, 'Schools'), overwrite=True, sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_mappings = arcpy.FieldMappings()\n",
    "# add tables to field mappings\n",
    "field_mappings.addTable('TAZ')\n",
    "field_mappings.addTable('Schools')\n",
    "\n",
    "\n",
    "# print names of fields in field mappings\n",
    "for field in field_mappings.fields:\n",
    "    print(field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create field mappings\n",
    "field_mappings = arcpy.FieldMappings()\n",
    "\n",
    "# add tables to field mappings\n",
    "field_mappings.addTable('TAZ')\n",
    "field_mappings.addTable('Schools')\n",
    "\n",
    "# for the output.\n",
    "enrollment = field_mappings.findFieldMapIndex(\"ENROLLMENT\")\n",
    "fieldmap = field_mappings.getFieldMap(enrollment)\n",
    " \n",
    "# Get the output field's properties as a field object\n",
    "field = fieldmap.outputField\n",
    " \n",
    "# Rename the field and pass the updated field object back into the field map\n",
    "field.name = \"Total_Enrollment\"\n",
    "field.aliasName = \"Total Enrollment\"\n",
    "fieldmap.outputField = field\n",
    " \n",
    "# Set the merge rule to mean and then replace the old fieldmap in the mappings object\n",
    "# with the updated one\n",
    "fieldmap.mergeRule = \"sum\"\n",
    "field_mappings.replaceFieldMap(enrollment, fieldmap)\n",
    "\n",
    "# spatial join that sums enrollment for each TAZ\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features   =sdf_taz,\n",
    "    join_features     =sdf_school,\n",
    "    out_feature_class =\"TAZ_School_Enrollment\",\n",
    "    join_operation    =\"JOIN_ONE_TO_ONE\",\n",
    "    join_type         =\"KEEP_ALL\",\n",
    "    field_mapping     =field_mappings,\n",
    "    match_option      =\"INTERSECT\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data \n",
    "sdf_taz_school = pd.DataFrame.spatial.from_featureclass(\"TAZ_School_Enrollment\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts\n",
    "> Forecast 2040 and 2050 development and population change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
