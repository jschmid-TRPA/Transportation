{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Travel Demand Model Data Inputs\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current working directory\n",
    "local_path = pathlib.Path().absolute()\n",
    "# set data path as a subfolder of the current working directory TravelDemandModel\\2022\\data\\\n",
    "data_dir = local_path.parents[0] / '2022/data'\n",
    "# set workspace\n",
    "arcpy.env.workspace = os.path.join(local_path, 'Workspace.gdb')\n",
    "# overwrite true\n",
    "arcpy.env.overwriteOutput = True\n",
    "# Set spatial reference to NAD 1983 UTM Zone 10N\n",
    "sr = arcpy.SpatialReference(26910)\n",
    "\n",
    "# global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "* old inputs: F:\\Research and Analysis\\misc\\Reid_Haefer\\Model\\model_update_2018\\data_inputs\\lodging_occupancy\n",
    "* Final inputs to produce: F:\\Transportation\\model\\scenario_base\\zonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\Lib\\site-packages\\arcgis\\features\\geo\\_accessor.py:1531: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._data[col] = array\n"
     ]
    }
   ],
   "source": [
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)\n",
    "#set spatial reference\n",
    "sdf_taz.spatial.sr\n",
    "\n",
    "# Get Unit Data\n",
    "units_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_units = get_fs_data_spatial_query(units_url, \"Year = 2022\")\n",
    "sdf_units.spatial.sr\n",
    "\n",
    "# Get Block Group Data\n",
    "block_groups_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/27'\n",
    "sdf_block_groups = get_fs_data_spatial(block_groups_url)\n",
    "sdf_block_groups = sdf_block_groups[(sdf_block_groups['YEAR'] == 2020) & (sdf_block_groups['GEOGRAPHY'] == 'Block Group')]\n",
    "sdf_block_groups.spatial.sr\n",
    "\n",
    "# Get VHR Data\n",
    "vhr_url = 'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\n",
    "sdf_vhr = get_fs_data_spatial(vhr_url)\n",
    "sdf_vhr.spatial.sr\n",
    "sdf_vhr = sdf_vhr[(sdf_vhr['Status'] == 'Active')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TAZ to Block Group Crosswalk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_block_group_crosswalk = make_taz_crosswalk(sdf_units, sdf_taz, sdf_block_groups)\n",
    "taz_block_group_crosswalk.to_csv('taz_block_group_crosswalk.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QAQC on vhrs and parcels\n",
    "df_vhr_comparison = pd.merge(sdf_vhr, sdf_units, left_on='APN', right_on='APN', how='left')\n",
    "missing_units = df_vhr_comparison[df_vhr_comparison['Residential_Units']==0]\n",
    "missing_units.to_csv('missing_units.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign VHRs to TAZs and then group by TAZ\n",
    "vhr_fc = sdf_vhr\n",
    "taz_fc = sdf_taz\n",
    "vhr_taz_feature_class = r\"in_memory\\vhr_geo\"\n",
    "\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features=vhr_fc,\n",
    "    join_features=taz_fc,\n",
    "    out_feature_class=vhr_taz_feature_class,\n",
    "    join_operation=\"JOIN_ONE_TO_MANY\",\n",
    "    join_type=\"KEEP_ALL\",\n",
    "    match_option=\"HAVE_THEIR_CENTER_IN\"\n",
    ")\n",
    "sdf_vhr_geo = pd.DataFrame.spatial.from_featureclass(vhr_taz_feature_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz_vhr_grouped = sdf_vhr_geo.groupby('TAZ').agg({'APN': 'count'}).reset_index()\n",
    "taz_vhr_grouped = taz_vhr_grouped.rename(columns={'APN': 'VHR_Count'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Socio Econ\n",
    "> TAZ by total_residential_units,census_occ_rate,total_occ_units,occ_units_low_inc,occ_units_med_inc,occ_units_high_inc,persons_per_occ_unit,total_persons,emp_retail,emp_srvc,emp_rec,emp_game,emp_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "df_census = get_fs_data(census_url)\n",
    "df_census_2022 = df_census[(df_census['year_sample'] == 2022) & (df_census['sample_level'] == 'block group')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Occupancy Data - B25002_003E = Vacant, B25002_002E = Occupied , B25004_006E = Vacant Seasonal\n",
    "occupancy_codes = ['B25002_003E','B25002_002E', 'B25004_006E']\n",
    "df_census_occupancy = df_census_2022[df_census_2022['variable_code'].isin(occupancy_codes)]\n",
    "df_census_occupancy = df_census_occupancy[['TRPAID', 'variable_code', 'value']]\n",
    "# pivot to wide format so we can calculate percentages and totals\n",
    "df_census_occupancy = df_census_occupancy.pivot(index='TRPAID', columns='variable_code', values='value').reset_index()\n",
    "# vacant units + occupied units = total units\n",
    "df_census_occupancy['total_units'] = df_census_occupancy['B25002_003E'] + df_census_occupancy['B25002_002E']\n",
    "# occupancy rate = occupied units / total units\n",
    "df_census_occupancy['occupancy_rate'] = df_census_occupancy['B25002_002E'] / df_census_occupancy['total_units']\n",
    "# seasonal rate = seasonal units / total units\n",
    "df_census_occupancy['seasonal_rate'] = df_census_occupancy['B25004_006E'] / df_census_occupancy['total_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Household Size Data - B25010_001E = Total Households\n",
    "df_census_household_size = df_census_2022[df_census_2022['variable_code'] == 'B25010_001E']\n",
    "df_census_household_size = df_census_household_size[['TRPAID', 'variable_code', 'value']]\n",
    "df_census_household_size = df_census_household_size.pivot(index='TRPAID', columns='variable_code', values='value').reset_index()\n",
    "df_census_household_size['household_size'] = df_census_household_size['B25010_001E']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize the income variables from the census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Codes by the category they fall into - Census categroy to broader category\n",
    "code_lookup = pd.read_csv('Lookup_Lists/occupancy_census_codes.csv')\n",
    "#Filter census so only variable codes in the code lookup are included\n",
    "df_census_income = df_census_2022[df_census_2022['variable_code'].isin(code_lookup['variable_code'])]\n",
    "#Create a new column that has a value from code lookup based on the variable code\n",
    "df_census_income['income_category'] = df_census_income['variable_code'].map(code_lookup.set_index('variable_code')['category'])\n",
    "#group by block group and income category and sum the values\n",
    "df_census_income = df_census_income.groupby(['TRPAID','income_category'])['value'].sum().reset_index()\n",
    "df_census_income = df_census_income.pivot(index='TRPAID', columns='income_category', values='value').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRPAID is a 16 digit ID, but it is imported as a float. Convert to string and to retain leading zeros\n",
    "df_census_household_size['TRPAID']= df_census_household_size['TRPAID'].astype(str).str.zfill(16)\n",
    "df_census_income['TRPAID']= df_census_income['TRPAID'].astype(str).str.zfill(16)\n",
    "# merge all the census data together\n",
    "df_census_occupancy_all = pd.merge(df_census_occupancy, df_census_household_size, on='TRPAID', how='left')\n",
    "df_census_all = pd.merge(df_census_occupancy_all, df_census_income, on='TRPAID', how='left')\n",
    "# rename columns of df_census_all\n",
    "column_rename = {\n",
    "    'B25002_003E': 'vacant_units',\n",
    "    'B25002_002E': 'occupied_units',\n",
    "    'B25004_006E': 'seasonal_units',\n",
    "    'High Income': 'high_income',\n",
    "    'Low Income': 'low_income',\n",
    "    'Medium Income': 'middle_income',\n",
    "}\n",
    "df_census_all.rename(columns=column_rename, inplace=True)\n",
    "# FIXME: remove this line once the data is fixed\n",
    "df_census_all.drop(columns=['B25010_001E'], inplace=True)\n",
    "# calculate proportions of income categories\n",
    "df_census_all['high_income_proportion'] = df_census_all['high_income'] / df_census_all['occupied_units']\n",
    "df_census_all['middle_income_proportion'] = df_census_all['middle_income'] / df_census_all['occupied_units']\n",
    "df_census_all['low_income_proportion'] = df_census_all['low_income'] / df_census_all['occupied_units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the proportions in sdf_taz_bg to assign proportion of block group values to taz\n",
    "taz_values_acs = taz_block_group_crosswalk.merge(df_census_all, left_on='TRPAID', right_on='TRPAID', how='left')\n",
    "taz_values_acs = taz_values_acs.merge(taz_vhr_grouped, on='TAZ', how='left')\n",
    "taz_values_acs.fillna(0, inplace=True)\n",
    "# Calculate the number of seasonal units we think are in each TAZ\n",
    "#Remove VHRs from seasonal units so that we can get just vacation/second homes\n",
    "#taz_values_acs['adjusted_seasonal_units'] = taz_values_acs['seasonal_units']-taz_values_acs['VHR_Count']\n",
    "#taz_values_acs['seasonal_rate'] = taz_values_acs['adjusted_seasonal_units'] / taz_values_acs['total_units']\n",
    "#Create proportional values based on how many proportion of residential units are in each TAZ\n",
    "taz_values_acs['adjusted_occupancy'] = taz_values_acs['occupancy_rate'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_high_income'] = taz_values_acs['high_income_proportion'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_middle_income'] = taz_values_acs['middle_income_proportion'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_low_income'] = taz_values_acs['low_income_proportion'] * taz_values_acs['Residential_Units_Proportion']\n",
    "taz_values_acs['adjusted_seasonal_rate'] = taz_values_acs['seasonal_rate'] * taz_values_acs['Residential_Units_Proportion']\n",
    "#Group by TAZ and sum the values\n",
    "taz_values_grouped_occupancy = taz_values_acs.groupby('TAZ').agg({'adjusted_occupancy': 'sum',\n",
    "                                                                  'adjusted_seasonal_rate': 'sum',\n",
    "                                                                  'adjusted_high_income':'sum',\n",
    "                                                                  'adjusted_middle_income': 'sum',\n",
    "                                                                  'adjusted_low_income': 'sum'}).reset_index()\n",
    "#This is just the input values for the TAZs\n",
    "taz_values_grouped_occupancy.to_csv('taz_calibration_values.csv', index=False)\n",
    "#This provides the raw data for troubleshooting\n",
    "taz_values_acs.to_csv('taz_values_acs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the proportions by the total number of units in the TAZ\n",
    "taz_residential_units = taz_block_group_crosswalk.groupby('TAZ')['Residential_Units'].sum().reset_index()\n",
    "taz_residential_units = taz_residential_units.merge(taz_values_grouped_occupancy, on='TAZ', how='left')\n",
    "taz_residential_units = taz_residential_units.merge(taz_vhr_grouped, on='TAZ', how='left')\n",
    "taz_residential_units['occupancy'] = taz_residential_units['adjusted_occupancy'] * taz_residential_units['Residential_Units']\n",
    "taz_residential_units['total_seasonal_units'] = taz_residential_units['adjusted_seasonal_rate'] * taz_residential_units['Residential_Units']\n",
    "taz_residential_units['adjusted_season_units'] = taz_residential_units['total_seasonal_units'] - taz_residential_units['VHR_Count']\n",
    "# Adjust income proportions by the total number of residential units and adjusted occupancy in each TAZ\n",
    "taz_residential_units['high_income'] = (taz_residential_units['adjusted_high_income'] * \n",
    "                                                    taz_residential_units['Residential_Units'] * \n",
    "                                                    taz_residential_units['adjusted_occupancy'])\n",
    "\n",
    "taz_residential_units['middle_income'] = (taz_residential_units['adjusted_middle_income'] * \n",
    "                                                    taz_residential_units['Residential_Units'] * \n",
    "                                                    taz_residential_units['adjusted_occupancy'])\n",
    "\n",
    "taz_residential_units['low_income'] = (taz_residential_units['adjusted_low_income'] * \n",
    "                                                taz_residential_units['Residential_Units'] * \n",
    "                                                taz_residential_units['adjusted_occupancy'])\n",
    "taz_residential_units.to_csv('taz_calibration_values_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total persons in each TAZ\n",
    "# total regional population is 55,836 from the decenial census\n",
    "\n",
    "# total persons in each TAZ = total persons in region * propotion of residents in TAZ\n",
    "\n",
    "# proportion of residents in TAZ = residential units in TAZ * household size in TAZ * residential occupancy rate in TAZ\n",
    "\n",
    "# propoportion of residents in TAZ/ sum(proportion of residents in TAZ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: Assign employees to TAZs\n",
    "* Data Axle data and CBP data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overnight Visitation - \n",
    ">TAZ by hotelmotel,resort,casino,campground,percentHouseSeasonal\n",
    "* hotelmotel = TAUs Available Per Day where TAU_TYPE = Hotel/Motel\n",
    "* resort     = TAUs Available Per Day where TAU_TYPE = Resort\n",
    "* casino     = TAUs Available Per Day where TAU_TYPE = Casino\n",
    "\n",
    "* campground = Sites available per day\n",
    "    \n",
    "* percentHouseSeasonal = (TRPA Residenital Units * Census Unoccupied Rate) - VHRs / (TRPA Residential Units * Census Unoccupied Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tourist Accommodation Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TAUs by TAZ * Occupancy Rate of TAU) * number of people per room\n",
    "\n",
    "# percent house seasonal = seasonal units * seasonal rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Tourist Accomodation Units data\n",
    "tau_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_tau = get_fs_data_spatial_query(tau_url, \"YEAR = 2022\")\n",
    "\n",
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Set TAU Type - Casino, Hotel/Motel, Resort, or VHR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set TAU_Type to null text field\n",
    "sdf_tau['TAU_Type'] = None\n",
    "# columns to keep\n",
    "tau_columns = ['APN',\n",
    "                'TouristAccommodation_Units', 'YEAR',\n",
    "                'JURISDICTION', 'COUNTY', 'OWNERSHIP_TYPE',\n",
    "                'EXISTING_LANDUSE', 'TAZ', 'TAU_Type',\n",
    "                'WITHIN_TRPA_BNDY', 'PARCEL_ACRES', 'PARCEL_SQFT', 'SHAPE']\n",
    "# filter to columns\n",
    "sdf_tau = sdf_tau[tau_columns]\n",
    "\n",
    "# get only parcels with tourist accomodation units\n",
    "sdf_tau = sdf_tau[sdf_tau['TouristAccommodation_Units'] > 0]\n",
    "\n",
    "# casino or resort parcels\n",
    "casino_apns = [# south shore\n",
    "                '1318-27-002-002','1318-27-002-005','1318-27-001-009','1318-27-001-021'\n",
    "               # north shore\n",
    "               '123-031-01', '123-042-01', '123-052-04', '123-042-15']\n",
    "\n",
    "resort_apns = [# LT resort, hyatt, hilton, >?\n",
    "                '127-280-02','029-480-004','027-090-025']\n",
    "\n",
    "# set TAU_Type feild values to Hotel/Motel, Casino, or Resort\n",
    "sdf_tau['TAU_Type'] = \"Hotel/Motel\"\n",
    "# if the APN is in the list of casino APNs, set the TAU Type to Casino\n",
    "sdf_tau.loc[sdf_tau['APN'].isin(casino_apns), 'TAU_Type'] = \"Casino\"\n",
    "# if the APN is in the list of resort APNs, set the TAU Type to Resort\n",
    "sdf_tau.loc[sdf_tau['APN'].isin(resort_apns), 'TAU_Type'] = \"Resort\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_tau.TAU_Type.value_counts()\n",
    "# get APNs with TAU_Type = Casino\n",
    "sdf_casino = sdf_tau[sdf_tau['TAU_Type'] == 'Casino']\n",
    "sdf_casino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join TAZ data to TAU data\n",
    "arcpy.SpatialJoin_analysis(sdf_tau, sdf_taz, 'taz_tau', \n",
    "                           'JOIN_ONE_TO_ONE', 'KEEP_ALL', \n",
    "                           match_option='HAVE_THEIR_CENTER_IN')\n",
    "\n",
    "# read in output of spatial join as sdf\n",
    "sdf_tau_taz = pd.DataFrame.spatial.from_featureclass('taz_tau')\n",
    "# set TAZ = to TAZ_1\n",
    "sdf_tau_taz['TAZ'] = sdf_tau_taz['TAZ_1']\n",
    "# keep columns\n",
    "sdf_tau_taz = sdf_tau_taz[tau_columns]\n",
    "\n",
    "# group by TAU_Type and sum of TouristAccommodation_Units within TAZ\n",
    "sdf_tau_taz_grouped = sdf_tau_taz.groupby(['TAU_Type', 'TAZ']).agg(\n",
    "                                                {'TouristAccommodation_Units': 'sum'}).reset_index()\n",
    "# unstack by TAU_Type as columns and TAZ as a column\n",
    "sdf_tau_taz_grouped_pivot = sdf_tau_taz_grouped.pivot(index='TAZ', \n",
    "                                                      columns='TAU_Type', \n",
    "                                                      values='TouristAccommodation_Units').reset_index()\n",
    "# merge to sdf_taz to get all tazs\n",
    "sdf_taz_tau = pd.merge(sdf_taz, sdf_tau_taz_grouped_pivot, how='left', on='TAZ')\n",
    "\n",
    "# rename columns\n",
    "sdf_taz_tau.rename(columns={'Hotel/Motel':'hotelmotel',\n",
    "                            'Casino':'casino',\n",
    "                            'Resort':'resort'}, inplace=True)\n",
    "\n",
    "# set columns\n",
    "sdf_taz_tau['campground'] = 0\n",
    "sdf_taz_tau['percentHouseSeasonal'] = 0\n",
    "\n",
    "# keep only columns of interest\n",
    "sdf_taz_tau = sdf_taz_tau[['TAZ', 'hotelmotel', 'casino', 'resort','campground','percentHouseSeasonal']]\n",
    "sdf_taz_tau = sdf_taz_tau.fillna(0)\n",
    "# cast all fields to int\n",
    "sdf_taz_tau = sdf_taz_tau.astype(int)\n",
    "\n",
    "# export to csv\n",
    "sdf_taz_tau.to_csv(os.path.join('OvernightVisitorZonalData_Summer.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campgrounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: calculate campground occupancy on model day and assign to TAZs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data - should be 18 campgrounds\n",
    "campground_url = 'https://maps.trpa.org/server/rest/services/Recreation/MapServer/1'\n",
    "sdf_campground =  get_fs_data_spatial_query(campground_url, \"RECREATION_TYPE='Campground'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Spatial Interpolation of Campground Occupancy Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to TAZ data\n",
    "# Get the data - should be 18 campgrounds\n",
    "campground_url = 'https://maps.trpa.org/server/rest/services/Recreation/MapServer/1'\n",
    "sdf_campground =  get_fs_data_spatial_query(campground_url, \"RECREATION_TYPE='Campground'\")\n",
    "\n",
    "# campground occupancy rate data\n",
    "dfCamp = pd.read_csv(os.path.join(data_dir,'Campground_Visitation.csv'))\n",
    "dfCamp_2022 = dfCamp.loc[dfCamp['Year'] == 2022]\n",
    "\n",
    "# merge campground data with occupancy rate data on campground name\n",
    "sdf_campground = sdf_campground.merge(dfCamp_2022, left_on='RECREATION_NAME', right_on='Campground', \n",
    "                                      how='left', indicator=True)\n",
    "\n",
    "# keep only columns of interest\n",
    "sdf_campground = sdf_campground[['RECREATION_NAME', 'Occupancy_Rate','SHAPE']]\n",
    "\n",
    "# filter sdf_campground to only campgrounds with occupancy rate data\n",
    "sdf_campground = sdf_campground[sdf_campground['Occupancy_Rate'].notnull()]\n",
    "\n",
    "# IDW to get the occupancy rate for each campground\n",
    "# set the output cell size\n",
    "cell_size = 500\n",
    "# set the power parameter\n",
    "power = 2\n",
    "# set the search radius\n",
    "search_radius = 5000\n",
    "# set the output raster\n",
    "out_raster = 'campground_occupancy_rate'\n",
    "# run the IDW\n",
    "arcpy.sa.Idw(in_features=sdf_campground, \n",
    "             z_field='Occupancy_Rate', \n",
    "             cell_size=cell_size, \n",
    "             power=power, \n",
    "             search_radius=search_radius).save(out_raster)\n",
    "\n",
    "# spatial join to campground points with NaN occupancy rate\n",
    "sdf_campground_nan = sdf_campground[sdf_campground['Occupancy_Rate'].isnull()]\n",
    "# spatial join to campground points with NaN occupancy rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Join and Merge Camground sites with tazs and group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data - should be 18 campgrounds\n",
    "campground_url = 'https://maps.trpa.org/server/rest/services/Recreation/MapServer/1'\n",
    "sdf_campground =  get_fs_data_spatial_query(campground_url, \"RECREATION_TYPE='Campground'\")\n",
    "\n",
    "# campground occupancy rate data\n",
    "dfCamp = pd.read_csv(os.path.join(data_dir,'Campground_Visitation.csv'))\n",
    "dfCamp_2022 = dfCamp.loc[dfCamp['Year'] == 2022]\n",
    "\n",
    "# merge campground data with occupancy rate data on campground name\n",
    "sdf_campground = sdf_campground.merge(dfCamp_2022, left_on='RECREATION_NAME', right_on='Campground', \n",
    "                                      how='left', indicator=True)\n",
    "\n",
    "# spatial join TAZ data to campground data\n",
    "arcpy.SpatialJoin_analysis(sdf_campground, sdf_taz, 'taz_campground', \n",
    "                           'JOIN_ONE_TO_ONE', 'KEEP_ALL', \n",
    "                           match_option='HAVE_THEIR_CENTER_IN')\n",
    "\n",
    "# read in output of spatial join as sdf\n",
    "sdf_campground_taz = pd.DataFrame.spatial.from_featureclass('taz_campground')\n",
    "\n",
    "# get sites sold by multiplying the number of sites by the occupancy rate\n",
    "sdf_campground_taz['SitesSold'] = sdf_campground_taz['Total_Sites'] * sdf_campground_taz['Occupancy_Rate']\n",
    "\n",
    "# group by TAZ and sum of sites sold within TAZ\n",
    "sdf_campground_taz_grouped = sdf_campground_taz.groupby('TAZ').agg(\n",
    "                                                {'SitesSold': 'sum'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupancy Rates\n",
    "> TAZ by hotelmotel,resort,casino,campground,house,seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lodging Occupancy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: calculate occupancy rates for hotels and VHRs and assign to TAZs\n",
    "\n",
    "* Placer has Occupancy data at the TOT tax district. Josh will get the spatial file from Placer County GIS. \n",
    "* City of South Lake has hotel level occupancy data that needs to be converted to a spatial file. Reports live here: https://www.cityofslt.us/805/Zone-Detail-Reports \n",
    "* Douglas County has occupancy rates from the Casino reports: https://gaming.nv.gov/about/abstract/report/\n",
    "* Washoe County has occupancy rates at the District level from RSCVA (single number by type of occupancy) \"F:\\Research and Analysis\\Visitation\\occupancy\\Washoe B Occupied Rooms by Market Segment - 2022.xlsx\"\n",
    "* Rest of El Dorado County? is only VHRs, estimating Occupancy Rates based on TOT rates F:\\Research and Analysis\\Visitation\\occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_fs_data_spatial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13444\\3078683283.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get VHR data - this is current, no way to get historical data outside of the City of South Lake Tahoe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvhr_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msdf_vhr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_fs_data_spatial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvhr_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msdf_vhr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_fs_data_spatial' is not defined"
     ]
    }
   ],
   "source": [
    "# Get VHR data - this is current, no way to get historical data outside of the City of South Lake Tahoe\n",
    "vhr_url = 'https://maps.trpa.org/server/rest/services/VHR/MapServer/0'\n",
    "sdf_vhr = get_fs_data_spatial(vhr_url)\n",
    "sdf_vhr.spatial.sr = sr\n",
    "\n",
    "# Get Tourist Accomodation Units data\n",
    "tau_url = 'https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2'\n",
    "sdf_units_2022 = get_fs_data_spatial_query(tau_url, \"YEAR = 2022\")\n",
    "sdf_units_2022.spatial.sr = sr\n",
    "\n",
    "# occupancy feature class as a spatial dataframe\n",
    "sdfOcc = pd.DataFrame.spatial.from_featureclass(\"Tahoe_OccupancyRate_Zones\")\n",
    "sdfOcc.spatial.sr = sr\n",
    "\n",
    "# get table from geodatabase\n",
    "occupancy_rate = pd.DataFrame.spatial.from_table(\"OccupancyRates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use zip to create a list of tuples of the unique combinations of Zone_ID, Timeframe, and Temporal_Scale\n",
    "zone_id = list(zip(occupancy_rate['Zone_ID'], occupancy_rate['Timeframe'], occupancy_rate['Temporal_Scale']))\n",
    "for zone in zone_id:\n",
    "    print(zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if field is float64 fill NaN with 0\n",
    "for field in occupancy_rate.columns:\n",
    "    if occupancy_rate[field].dtype == 'float64':\n",
    "        occupancy_rate[field].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # occupancy rate table\n",
    "# occupancy_rate = pd.read_excel(os.path.join(data_dir,\"OccupancyRate_JS.xlsx\"))\n",
    "# occupancy_rate.Zone_ID.unique()\n",
    "# # fill numeric columns with 0\n",
    "# # occupancy_rate.fillna(0, inplace=True)                                                    \n",
    "# # set timeframe to str\n",
    "# occupancy_rate['Timeframe'] = occupancy_rate['Timeframe'].astype(str)\n",
    "# # if field is float64 fill NaN with 0\n",
    "# for field in occupancy_rate.columns:\n",
    "#     if occupancy_rate[field].dtype == 'float64':\n",
    "#         occupancy_rate[field].fillna(0, inplace=True)\n",
    "# # convert to int\n",
    "# occupancy_rate.Report_RoomsAvailable = occupancy_rate.Report_RoomsAvailable.astype(int)\n",
    "# occupancy_rate.Report_RoomsRented = occupancy_rate.Report_RoomsRented.astype(int)\n",
    "# # to csv\n",
    "# occupancy_rate.to_csv('occupancy_rate.csv', index=False)\n",
    "# # export to geodatabase\n",
    "# occupancy_rate.spatial.to_table(\"Tahoe_OccupancyRates\", overwrite=True, format=\"TABULAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coerce Timeframe to string\n",
    "occupancy_rate['Timeframe'] = occupancy_rate['Timeframe'].astype(str)\n",
    "\n",
    "# # strip off 00:00:00\n",
    "occupancy_rate['Timeframe'] = occupancy_rate['Timeframe'].str.slice(0,10)\n",
    "\n",
    "# filter for date(2022, 8, 1, 0, 0), 'Q4 21-22', and  'Q3 2022' using the isin method and .loc\n",
    "df = occupancy_rate.loc[occupancy_rate['Timeframe'].isin(['Q4 21-22', 'Q3 2022','2022-08-01'])]\n",
    "\n",
    "# # filter for Hotel/Motel and Casino\n",
    "df = df.loc[~df['RoomType'].isin(['VHR'])]\n",
    "df.Zone_ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occupancy feature class as a spatial dataframe\n",
    "sdfOcc = pd.DataFrame.spatial.from_featureclass(\"Tahoe_OccupancyRate_Zones\")\n",
    "sdfOcc.spatial.sr = sr\n",
    "\n",
    "# filter for date(2022, 8, 1, 0, 0), 'Q4 21-22', and  'Q3 2022' using the isin method and .loc\n",
    "df = occupancy_rate.loc[occupancy_rate.Timeframe.isin(['Q4 21-22', 'Q3 2022','2022-08-01']) & ~occupancy_rate.RoomType.isin(['VHR'])]\n",
    "\n",
    "# cast Zone_ID as type string\n",
    "df['Zone_ID'].astype(str)\n",
    "\n",
    "# merge occupancy rate data to occupancy zones\n",
    "sdf = pd.merge(sdfOcc, df, left_on='OccupancyRate_ZoneID', right_on='Zone_ID', how='outer', indicator=True)\n",
    "\n",
    "# export sdf to feature class\n",
    "sdf.spatial.to_featureclass(location=os.path.join('Workspace.gdb', 'OccupancyRate_Zones'), overwrite=True)\n",
    "\n",
    "# check value counts of merge\n",
    "sdf._merge.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Filter Occupancy Rates to August timeframe and join to zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occupance rate table with \n",
    "\n",
    "# get table from geodatabase\n",
    "occupancy_rate = pd.DataFrame.spatial.from_table(\"OccupancyRates\")\n",
    "\n",
    "df = occupancy_rate\n",
    "# filter for date(2022, 8, 1, 0, 0), 'Q4 21-22', and  'Q3 2022' using the isin method and .loc\n",
    "# df = occupancy_rate.loc[occupancy_rate['Timeframe'].isin(['Q4 21-22', 'Q3 2022','2022-08-01'])]\n",
    "\n",
    "# cast Zone_ID as type string\n",
    "df['Zone_ID'].astype(str)\n",
    "\n",
    "# # filter out rows with VHR room type\n",
    "# df = df.loc[~df['RoomType'].isin(['VHR'])]\n",
    "df.Zone_ID.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Merge CA parcels and VHR parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter vhr layer to active status\n",
    "sdf_vhr = sdf_vhr.loc[sdf_vhr['Status'] == 'Active']\n",
    "# merge parcel 2022 with parcel VHR\n",
    "sdf_units_2022 = sdf_units_2022.merge(sdf_vhr, on='APN', how='left', indicator=True)\n",
    "# calculate VHR = Yes if VHR is in the parcel\n",
    "sdf_units_2022['VHR'] = 'No'\n",
    "sdf_units_2022.loc[sdf_units_2022['_merge'] == 'both', 'VHR'] = 'Yes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Join parcels with units to occupancy rate zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get occupancy rate for VHRs using IDW\n",
    "# get occupancy rate for TAUs using IDW\n",
    "# set the output cell size\n",
    "cell_size = 30\n",
    "# set the power parameter\n",
    "power = 2\n",
    "# set the search radius\n",
    "search_radius = 5000\n",
    "# set the output raster\n",
    "out_raster = 'tau_occupancy_rate'\n",
    "# run the IDW\n",
    "arcpy.sa.Idw(in_features=sdf_tau, \n",
    "             z_field='Occupancy_Rate', \n",
    "             cell_size=cell_size, \n",
    "             power=power, \n",
    "             search_radius=search_radius).save(out_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay units with occupancy zones\n",
    "arcpy.SpatialJoin_analysis(sdf_units_2022, 'OccupancyRate_Zones', \"SpJoin_Units_OccupancyRates\", \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")\n",
    "# read in output of spatial join as sdf\n",
    "sdf_units_occ = pd.DataFrame.spatial.from_featureclass('SpJoin_Units_OccupancyRates')\n",
    "sdf_units_occ.spatial.sr = sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Join parcels to TAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overlay taz with units\n",
    "# Spatial Join\n",
    "arcpy.SpatialJoin_analysis(sdf_units_2022, sdf_taz, \"SpJoin_Units_TAZ\", \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", \"\", \"HAVE_THEIR_CENTER_IN\", \"\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Interpolate Occupancy Rate - Inverse Distance Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# occupancy rate interpolation \n",
    "# Interpolate Points\n",
    "# TAUs to points using in_memory\n",
    "arcpy.management.FeatureToPoint(\"SpJoin_Units_TAZ\", \"in_memory\\\\TAU_Points\", \"INSIDE\")\n",
    "# VHR to points using in_memory\n",
    "arcpy.management.FeatureToPoint(\"VHR\", \"in_memory\\\\VHR_Points\", \"INSIDE\")\n",
    "\n",
    "# interpolate occupancy rates for TAUs\n",
    "arcpy.ddd.IDW(\"TAU_Points\", \"Report_OccupancyRate\", \"in_memory\\\\TAU_OccupancyRate\", \"0.1\", \"2\", \"NBRTYPE=Standard SMOOTH=0.1\", \"\")\n",
    "# interpolate occupancy rates for VHRs\n",
    "arcpy.ddd.IDW(\"VHR_Points\", \"Report_OccupancyRate\", \"in_memory\\\\VHR_OccupancyRate\", \"0.1\", \"2\", \"NBRTYPE=Standard SMOOTH=0.1\", \"\")\n",
    "\n",
    "# convert raster to polygon \n",
    "arcpy.RasterToPolygon_conversion(\"in_memory\\\\TAU_OccupancyRate\", \"in_memory\\\\TAU_OccupancyRate_Polygon\", \n",
    "                                 \"NO SIMPLIFY\", \"VALUE\")\n",
    "arcpy.RasterToPolygon_conversion(\"in_memory\\\\VHR_OccupancyRate\", \"in_memory\\\\VHR_OccupancyRate_Polygon\",\n",
    "                                 \"NO_SIMPLIFY\", \"VALUE\") \n",
    "\n",
    "# convert to spatial dataframes\n",
    "sdf_tau_occ = pd.DataFrame.spatial.from_featureclass('in_memory\\\\TAU_OccupancyRate_Polygon')\n",
    "sdf_vhr_occ = pd.DataFrame.spatial.from_featureclass('in_memory\\\\VHR_OccupancyRate_Polygon')\n",
    "\n",
    "# merge occupancy rates to TAUs\n",
    "sdf_tau_occ = pd.merge(sdf_tau_occ, sdf_units_occ, on='APN', how='left')\n",
    "\n",
    "# set VHR_OccupancyRate to 0 if null\n",
    "sdf['VHR_OccupancyRate'].fillna(0, inplace=True)\n",
    "\n",
    "# zonal stats for TAUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model Rooms Rented by TAZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of rooms rented for TAUs and VHRs\n",
    "sdf_tau_occ['rooms_rented'] = sdf_tau_occ['Report_RoomsAvailable'] * sdf_tau_occ['Report_OccupancyRate']\n",
    "sdf_vhr_occ['rooms_rented'] = sdf_vhr_occ['Report_RoomsAvailable'] * sdf_vhr_occ['Report_OccupancyRate']\n",
    "\n",
    "# group by TAZ and sum rooms rented\n",
    "sdf_tau_occ_grouped = sdf_tau_occ.groupby('TAZ').agg({'rooms_rented': 'sum'}).reset_index()\n",
    "sdf_vhr_occ_grouped = sdf_vhr_occ.groupby('TAZ').agg({'rooms_rented': 'sum'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Housing Occupancy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: estimate household size in each occupied housing unit\n",
    "* get total Residential Units aggregated to TAZ\n",
    "* get total VHRs aggregated to TAZ\n",
    "* apply occupancy rate from ACS\n",
    "* ACS 2022 by Block Group - household size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Houshold Block Group data\n",
    "df_census_household_size = df_census_2022[df_census_2022['variable_code'] == 'B25010_001E']\n",
    "df_census_household_size = df_census_household_size[['TRPAID', 'variable_code', 'value']]\n",
    "df_census_household_size_taz = taz_block_group_crosswalk.merge(df_census_household_size, on='TRPAID', how='left')\n",
    "df_census_household_size_taz['household_size_proportion'] = df_census_household_size_taz['value']*df_census_household_size_taz['Residential_Units_Proportion']\n",
    "taz_household_size = df_census_household_size_taz.groupby('TAZ')['household_size_proportion'].sum().reset_index()\n",
    "taz_household_size.to_csv('taz_household_size.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Enrollment\n",
    "> TAZ by elementary_school_enrollment,middle_school_enrollment,high_school_enrollment,college_enrollment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Purpose: Collate school enrollment files\n",
    "* create spatial file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get School Enrollment data\n",
    "school_url_table     = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/32'\n",
    "df_school_enrollment = get_fs_data(school_url_table)\n",
    "\n",
    "# Get School Enrollment data - spatial\n",
    "school_url_spatial = 'https://maps.trpa.org/server/rest/services/Datadownloader_PlanningandJurisdictions/MapServer/14'\n",
    "sdf_school         = get_fs_data_spatial(school_url_spatial)\n",
    "\n",
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set Type to Null\n",
    "sdf_school['TYPE'] = None\n",
    "# set SchoolType to 'elementary' if it contains 'elementary' or 'magnet' or 'academy'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('elementary', case=False), 'TYPE'] = 'Elementary School'\n",
    "# set SchoolType to 'middle' if it contains 'middle'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('middle', case=False), 'TYPE'] = 'Middle School'\n",
    "# set SchoolType to 'high' if it contains 'high'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('high', case=False), 'TYPE'] = 'High School'\n",
    "# set SchoolType to 'college' if it contains 'college'\n",
    "sdf_school.loc[sdf_school['NAME'].str.contains('college', case=False), 'TYPE'] = 'College'\n",
    "# set SchoolType to 'other' if it it does not contain any of the above\n",
    "sdf_school.loc[sdf_school['TYPE'].isnull(), 'TYPE'] = 'Elementary School'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join TAZs to School points\n",
    "sdf_school_taz = sdf_school.spatial.join(sdf_taz, how='inner')\n",
    "# group by TYPE and sum of Enrollment within TAZ \n",
    "sdf_school_taz_grouped = sdf_school_taz.groupby(['TYPE', 'TAZ']).agg(\n",
    "                                                {'ENROLLMENT': 'sum'}).reset_index()\n",
    "# unstack by TYPE as columns and TAZ as a column\n",
    "sdf_school_taz_grouped_pivot = sdf_school_taz_grouped.pivot(index='TAZ', \n",
    "                                                            columns='TYPE', \n",
    "                                                            values='ENROLLMENT').reset_index()\n",
    "# merge to sdf_taz to get all tazs\n",
    "sdf_taz_school = pd.merge(sdf_taz, sdf_school_taz_grouped_pivot, how='left', on='TAZ')\n",
    "\n",
    "# drop SHAPE column\n",
    "sdf_taz_school = sdf_taz_school.drop(columns='SHAPE')\n",
    "# fill NA with 0 for all rows\n",
    "sdf_taz_school = sdf_taz_school.fillna(0)\n",
    "# cast all fields to int\n",
    "sdf_taz_school = sdf_taz_school.astype(int)\n",
    "# rename columns\n",
    "sdf_taz_school.rename(columns={'Elementary School':'elementary_school_enrollment',\n",
    "                               'Middle School':'middle_school_enrollment',\n",
    "                               'High School':'high_school_enrollment',\n",
    "                               'College':'college_enrollment'}, inplace=True)\n",
    "\n",
    "# export to csv\n",
    "sdf_taz_school.to_csv(os.path.join('SchoolEnrollment.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_taz_school"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### other way "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_school_enrollment_22 = df_school_enrollment[df_school_enrollment['Year'] == '2022-2023']\n",
    "# Add a row for LTCC - Lake Tahoe Community College\n",
    "ltcc = {'School_Name': 'Lake Tahoe Community College', 'Level_': 'College', 'Enrollment': 2909}\n",
    "df_school_enrollment_22 = pd.concat([df_school_enrollment_22, pd.DataFrame([ltcc])], ignore_index=True)\n",
    "# join school spatial to school table\n",
    "sdf_school_enroll = pd.merge(sdf_school, df_school_enrollment, left_on='SchoolID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TAZ data\n",
    "taz_url = 'https://maps.trpa.org/server/rest/services/Transportation_Planning/MapServer/6'\n",
    "sdf_taz = get_fs_data_spatial(taz_url)\n",
    "\n",
    "# Get School Enrollment data - spatial\n",
    "school_url_spatial = 'https://maps.trpa.org/server/rest/services/Datadownloader_PlanningandJurisdictions/MapServer/14'\n",
    "sdf_school         = get_fs_data_spatial(school_url_spatial)\n",
    "\n",
    "\n",
    "# keep only the columns we need; SHAPE and TAZ for TAZ and SHAPE and ENROLLMENT for schools\n",
    "sdf_taz = sdf_taz[['TAZ', 'SHAPE']]\n",
    "sdf_school = sdf_school[['ENROLLMENT', 'SHAPE']]\n",
    "\n",
    "# convert to feature class\n",
    "sdf_taz.spatial.to_featureclass(location=os.path.join(arcpy.env.workspace, 'TAZ'), overwrite=True, sanitize_columns=False)\n",
    "sdf_school.spatial.to_featureclass(location=os.path.join(arcpy.env.workspace, 'Schools'), overwrite=True, sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_mappings = arcpy.FieldMappings()\n",
    "# add tables to field mappings\n",
    "field_mappings.addTable('TAZ')\n",
    "field_mappings.addTable('Schools')\n",
    "\n",
    "\n",
    "# print names of fields in field mappings\n",
    "for field in field_mappings.fields:\n",
    "    print(field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create field mappings\n",
    "field_mappings = arcpy.FieldMappings()\n",
    "\n",
    "# add tables to field mappings\n",
    "field_mappings.addTable('TAZ')\n",
    "field_mappings.addTable('Schools')\n",
    "\n",
    "# for the output.\n",
    "enrollment = field_mappings.findFieldMapIndex(\"ENROLLMENT\")\n",
    "fieldmap = field_mappings.getFieldMap(enrollment)\n",
    " \n",
    "# Get the output field's properties as a field object\n",
    "field = fieldmap.outputField\n",
    " \n",
    "# Rename the field and pass the updated field object back into the field map\n",
    "field.name = \"Total_Enrollment\"\n",
    "field.aliasName = \"Total Enrollment\"\n",
    "fieldmap.outputField = field\n",
    " \n",
    "# Set the merge rule to mean and then replace the old fieldmap in the mappings objecta\n",
    "# with the updated one\n",
    "fieldmap.mergeRule = \"sum\"\n",
    "field_mappings.replaceFieldMap(enrollment, fieldmap)\n",
    "\n",
    "# spatial join that sums enrollment for each TAZ\n",
    "arcpy.analysis.SpatialJoin(\n",
    "    target_features   =sdf_taz,\n",
    "    join_features     =sdf_school,\n",
    "    out_feature_class =\"TAZ_School_Enrollment\",\n",
    "    join_operation    =\"JOIN_ONE_TO_ONE\",\n",
    "    join_type         =\"KEEP_ALL\",\n",
    "    field_mapping     =field_mappings,\n",
    "    match_option      =\"INTERSECT\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data \n",
    "sdf_taz_school = pd.DataFrame.spatial.from_featureclass(\"TAZ_School_Enrollment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasts\n",
    "> Forecast 2040 and 2050 development and population change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2022 development units\n",
    "devhistoryURL = \"https://maps.trpa.org/server/rest/services/Existing_Development/MapServer/2\"\n",
    "parcel_history = get_fs_data_spatial(devhistoryURL)\n",
    "\n",
    "# global variables\n",
    "years = [2012, 2018, 2019, 2020, 2021, 2022, 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total residential units by year\n",
    "def get_totals(parcels, years):\n",
    "    # total\n",
    "    total = pd.DataFrame(columns=['Year', 'Residential_Units'])\n",
    "    for year in years:\n",
    "        # filter parcel_history by year\n",
    "        parcel_history_year = parcels.loc[parcels['YEAR'] == year]\n",
    "        # get sum of Residential Units in parcel_history\n",
    "        resTotal = parcel_history_year['Residential_Units'].sum()\n",
    "\n",
    "        # add new row using concat\n",
    "        total = pd.concat([total, pd.DataFrame({'Year': [year], 'Residential_Units': [resTotal]})])\n",
    "    return total\n",
    "\n",
    "# get total residential units by year\n",
    "total = get_totals(parcel_history, years)\n",
    "# calculate percentage change in residential units year over year\n",
    "total['Percent_Change'] = (total['Residential_Units'].pct_change())*100\n",
    "# create a new column for the difference in residential units year over year\n",
    "total['Difference'] = total['Residential_Units'].diff()\n",
    "\n",
    "total\n",
    "# export to csv\n",
    "total.to_csv('total_residential_units_by_year.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Old Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unit table as pandas dataframe\n",
    "unitsTable = pd.read_csv(r\"C:\\Users\\mbindl\\Documents\\GitHub\\Reporting\\data\\CumulativeAccounting_2012to2023_Updated.csv\", low_memory=False)\n",
    "# get rid of columns after YEAR\n",
    "unitsTable.drop(unitsTable.columns[unitsTable.columns.get_loc(\"YEAR\")+1:], axis=1,inplace=True)\n",
    "# get total residential units by year\n",
    "total = get_totals(unitsTable, years)\n",
    "# calculate percentage change in residential units year over year\n",
    "total['Percent_Change'] = (total['Residential_Units'].pct_change())*100\n",
    "# create a new column for the difference in residential units year over year\n",
    "total['Difference'] = total['Residential_Units'].diff()\n",
    "\n",
    "# export to csv\n",
    "total.to_csv('total_residential_units_by_year_OG.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_residential_units - base_2018 \n",
    "# forecast will be for 2040 and 2050 \n",
    "# rate of development will be based on the current rate of development from the last 12 years (back to 2012)\n",
    "    # current rate will not get us to full build out and will be adjusted to get to full build out by 2050\n",
    "# total_residential_units = base_2018 + (rate_of_development * (2040 - 2018))\n",
    "\n",
    "# forecast max build out will be 2050\n",
    "#  still going to build out all the residential units and then revisit how conversions of TAUs and CFA will be handled\n",
    "\n",
    "# GIS exercise of where the new residential units will be built\n",
    "# 1. get the land use data and see if we can get the residential units on vacant and underbuilt parcels\n",
    "\n",
    "# For TAUs and CFA we only built out what was in the pipeline\n",
    "\n",
    "# Total Occupied Units = Total Residential Units - Vacant Units\n",
    "    # based on block group rate and TAZ crosswalk assigned to Parcel level units\n",
    "# Occupied Units by Income Level = Total Occupied Units * % of Income Level in Block Group\n",
    "    # based on block group rate and TAZ crosswalk assigned to Parcel level units\n",
    "\n",
    "# Lodging Occupany Rates by Tax Rate Zone\n",
    "    # Air DNA? for VHR occupancy rates\n",
    "    # Seasonal Units will be based on the % of seasonal units in the block group?\n",
    "\n",
    "# Adjusted occupancy rates for Residential units to be based on population change to decennial census\n",
    "    # double check total persons in the model against the decennial census population and then apply the rate?\n",
    "\n",
    "# use adjusted ACS numbers to make all the input factors match the same source\n",
    "    # use the 2022 ACS data at the Basin level for all the input factors\n",
    "        # Block Group level data will be to noisy and not as accurate as the Basin level data\n",
    "\n",
    "# forecast growth at the Basin level and show some population growth...\n",
    "    # out year will be 2050 and show the growth in the model at 0.5% per year\n",
    "    # show the growth in the model at 1.0% per year? or use the decennial census growth rate?\n",
    "        # which was 0.04% per year from 2010 to 2020 annualized\n",
    "\n",
    "# show the growth in the model at 0.004% per year? or use the decennial census growth rate?\n",
    "    # adding 3000 units of affordable housing in the model and get 6,000 person increase in population\n",
    "\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
